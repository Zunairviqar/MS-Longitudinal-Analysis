{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a trained BIANCA model on Different Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to document the process to test a trained model of BIANCA and to have a script that allows re-doing automation of a testing process. After using the BIANCA Model, an analysis is generated on the results, the output of which is in HTML Format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is only for analysing a Single Timepoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we select the files that are to be input by the User as the Flair Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated BIANCA Training/Testing Files/ms_013_tp3/ms_013_tp3_flair_brain.nii.gz\n",
      "ms_013_tp3_flair_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "''\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "''\n",
    "flair_image_path = filedialog.askopenfilename() # Returns opened path as str\n",
    "print(flair_image_path) \n",
    "flair_image_name = flair_image_path.split('/')[-1]\n",
    "print(flair_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also ask the user to input a T1 Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated BIANCA Training/Testing Files/ms_013_tp3/ms_013_tp3_T1_brain.nii.gz\n",
      "ms_013_tp3_T1_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "''\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "''\n",
    "t1_image_path = filedialog.askopenfilename() # Returns opened path as str\n",
    "print(t1_image_path) \n",
    "t1_image_name = t1_image_path.split('/')[-1]\n",
    "print(t1_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then create a directory where the analysis is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "today = date.today()\n",
    "directory_name = 'Testing-' + str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ms/Desktop/BIANCA_Single_Testing_Notebook\n"
     ]
    }
   ],
   "source": [
    "# Parent Directory path\n",
    "x = os.getcwdb()\n",
    "#print(x)\n",
    "y = str(x).replace(\"b'\", '')\n",
    "#print(y)\n",
    "z = y.replace(\"'\", '')\n",
    "parent_dir = z\n",
    "print(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(parent_dir, directory_name)\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the path to store the files in the \"Training_{today's date} folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = parent_dir + \"/\" +directory_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also ask for the user to select the 'Training_{date}' folder to extract the dependent information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-05-17\n"
     ]
    }
   ],
   "source": [
    "training_folder_path = filedialog.askdirectory() # Returns opened path as str\n",
    "print(training_folder_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We perform Brain Extraction on Both the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Storing the Brain Extracted Flair Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair_brain_extracted = \"single_timepoint_flair_brain_extracted.nii.gz\"\n",
    "flair_brain_extracted = flair_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the directory where the flair image is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = flair_image_path.replace(\"/\" + flair_image_name, ' ').strip()\n",
    "directory_path = directory_path.replace(' ', '\\ ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceeding with the brain extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = os.popen(\n",
    "    f\"cd {directory_path} && cp {flair_image_name} {storage_path}/{flair_brain_extracted}\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating the same process for the T1 Brain Image to obtain the brain extracted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1_brain_extracted = \"single_timepoint_t1_Brain.nii.gz\"\n",
    "t1_brain_extracted = t1_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = os.popen(\n",
    "    f\"cd {directory_path} && cp {t1_image_name} {storage_path}/{t1_brain_extracted}\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we Resample the Flair Brain Image into the Dimensions on which our BIANCA Model was trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we check the dimensions of our Flair Brain Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimensions(file_name, printvals):\n",
    "    p = os.popen(\n",
    "        f\"cd {directory_name} && fslinfo {file_name}\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        #print(output)\n",
    "        output = output.replace(\"\\t\", \"\\n\")\n",
    "        file_info = output.split(\"\\n\")\n",
    "        while '' in file_info:\n",
    "            file_info.remove('')\n",
    "        #print(file_info)\n",
    "        dim1 = file_info[3]\n",
    "        dim2 = file_info[5]\n",
    "        dim3 = file_info[7]\n",
    "        if printvals== True:\n",
    "            print(\"Dimensions of: \", file_name)\n",
    "            print(dim1,dim2,dim3)\n",
    "        return(dim1,dim2,dim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:  ms_013_tp3_flair_brain.nii.gz\n",
      "256 256 40\n"
     ]
    }
   ],
   "source": [
    "flair_dimensions = check_dimensions(flair_brain_extracted, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we check the metadata file that we had stored in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('256', '256', '40')\n"
     ]
    }
   ],
   "source": [
    "file = open(f\"{training_folder_path}/metadata.txt\", \"r\")\n",
    "\n",
    "# Accessing the metadata file\n",
    "contents = file.read().split(\"\\n\")\n",
    "dims = contents[0].split(\",\")\n",
    "# Retrieving the dimensions\n",
    "bianca_dimensions = (dims[0], dims[1], dims[2])\n",
    "print(bianca_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_002_tp1_flair_brain.nii.gz\n",
      "ms_002_tp1\n"
     ]
    }
   ],
   "source": [
    "reference_image = contents[1]\n",
    "print(reference_image)\n",
    "reference_folder = \"_\".join(reference_image.split(\"_\")[0:3])\n",
    "print(reference_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we check if the dimensions of the selected FLAIR Image are different from the BIANCA Training Set Dimensions. If so, we perform the resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the dimensions of the BIANCA Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions Match!\n"
     ]
    }
   ],
   "source": [
    "if (flair_dimensions == bianca_dimensions):\n",
    "    print(\"Dimensions Match!\")\n",
    "else:\n",
    "    print(\"Dimensions do not match. Resampling required!\")\n",
    "    # Resampling the Flair Brain Image\n",
    "#     The following code bit needs to be modified\n",
    "#     p = os.popen(\n",
    "#         f\"cd {training_folder_path} && flirt -in {file} -ref {ref_img} -out {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz -omat {directory_name}/{folder_name}/resampling.mat -interp nearestneighbour -dof 6\")\n",
    "#     if p:\n",
    "#         output = p.read()\n",
    "#         print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we register our Flair Brain Image onto the MNI Space to obtain the .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a pre-requisite to this step, we need the MNI Space reference file in order to register the resampled flair brains to MNI Space and retrieve the .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the location of this file is not fixed, we can go ahead and select the file path for the MNI Space file by running the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ms/Desktop/BIANCA_Single_Testing_Notebook/MNI152_2mm_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "''\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "''\n",
    "mni_file = filedialog.askopenfilename() # Returns opened path as str\n",
    "\n",
    "mni_directory = mni_file.replace(' ', '\\ ')\n",
    "print(mni_directory) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_to_mni = \"flair_brain_to_mni.nii.gz\"\n",
    "flair_to_mni_mat = \"flair_brain_to_mni.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Registering the FLAIR Brain Image to MNI Space\n",
    "p = os.popen(\n",
    "    f\"cd {directory_name} && flirt -in {flair_brain_extracted} -ref {mni_directory} -out {flair_to_mni} -omat {flair_to_mni_mat} -bins 256 -cost normcorr -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -dof 7 -interp nearestneighbour\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we register the T1 brain to the Flair Brain to get the t1_to_flair.nii.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_to_flair = \"t1_brain_to_flair_brain.nii.gz\"\n",
    "t1_to_flair_mat = \"t1_brain_to_flair_brain.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Registering the T1 Image to Flair Image\n",
    "p = os.popen(\n",
    "    f\"cd {directory_name} && flirt -dof 6 -in {t1_brain_extracted} -ref {flair_brain_extracted} -out {t1_to_flair} -omat {t1_to_flair_mat} -interp nearestneighbour\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Lesion Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we Generate the Masterfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterfile = f\"{directory_name}/masterfile.txt\"\n",
    "flair_lesion_mask = \"flair_lesion_mask.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(masterfile, 'w')\n",
    "file.write(flair_brain_extracted + ' ')\n",
    "file.write(t1_to_flair + ' ')\n",
    "file.write(flair_to_mni_mat + ' ')\n",
    "file.write(flair_lesion_mask + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we actually go ahead and use the trained BIANCA Model on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we need to locate the training_labels and mytraining files generated from the testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-05-17/mytraining\n"
     ]
    }
   ],
   "source": [
    "classifier = (f\"{training_folder_path}/mytraining\").replace(\" \", \"\\ \")\n",
    "print(classifier)\n",
    "bianca_output = \"bianca_output.nii.gz\"\n",
    "binary_bianca_output = \"bianca_output_bin.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd Testing-2022-05-25 && bianca --singlefile=Testing-2022-05-25/masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-05-17/mytraining  --querysubjectnum=1 --brainmaskfeaturenum=1 --featuresubset=1,2 --matfeaturenum=3 -o bianca_output.nii.gz -v\n"
     ]
    }
   ],
   "source": [
    "print(f\"cd {directory_name} && bianca --singlefile={masterfile} --loadclassifierdata={classifier}  --querysubjectnum=1 --brainmaskfeaturenum=1 --featuresubset=1,2 --matfeaturenum=3 -o {bianca_output} -v\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 4 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "Filenames = []\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-05-17/mytraining\n",
      "Training data is size (181166, 5)\n",
      "Loading query data\n",
      "  Query file list = ['ms_013_tp3_flair_brain.nii.gz', 't1_brain_to_flair_brain.nii.gz']\n",
      " ... reading image ms_013_tp3_flair_brain.nii.gz\n",
      " ... reading image t1_brain_to_flair_brain.nii.gz\n",
      " ... reading matrix flair_brain_to_mni.mat\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:170: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pixdims=im.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    }
   ],
   "source": [
    "p = os.popen(\n",
    "    f\"cd {directory_name} && bianca --singlefile=masterfile.txt --loadclassifierdata={classifier}  --querysubjectnum=1 --brainmaskfeaturenum=1 --featuresubset=1,2 --matfeaturenum=3 -o {bianca_output} -v\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Binary Extraction at a certain Threshold on our obtained BIANCA Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = os.popen(\n",
    "    f\"cd {directory_name} && fslmaths {bianca_output} -thr 0.9 -bin {binary_bianca_output}\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the Bianca Output result has been obtained, we move forward and generate a report on the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total WMH number for bianca_output.nii.gz with threshold 0.9 and minimum cluster size 1 is 205\n",
      " total volume for bianca_output.nii.gz with threshold 0.9 and minimum cluster size 1 is 6373.571777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As per https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA/Userguide#Performance_evaluation, \n",
    "# The command to run is:\n",
    "\n",
    "# bianca_cluster_stats <bianca_output_map> <threshold> <min_cluster_size> [<mask>]\n",
    "\n",
    "p = os.popen(\n",
    "    f\"cd {directory_name} && bianca_cluster_stats {bianca_output} 0.9 1\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the number and volume of lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n",
      "6373.571777\n"
     ]
    }
   ],
   "source": [
    "num_lesions = output.split(\"\\n\")[0].split(\" \")[-1]\n",
    "print(num_lesions)\n",
    "lesions_vol = output.split(\"\\n\")[1].split(\" \")[-1]\n",
    "print(lesions_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HTML file by the name of results.html should be generated, which would contain the number of lesions and the total volume of those lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2 = open(f\"{directory_name}/results.html\", \"w\")\n",
    "file2.write(\"<!DOCTYPE html>\\n\")\n",
    "file2.write('<html lang=\"en\" dir=\"ltr\">')\n",
    "file2.write(\"<head>\")\n",
    "file2.write(\"<title>BIANCA RESULTS</title>\")\n",
    "file2.write(\"</head>\")\n",
    "file2.write(\"<body>\")\n",
    "file2.write(\"<h2>BIANCA Results Are:</h2>\\n\")\n",
    "file2.write(f\"<p>Number of Lesions: {num_lesions}</p>\\n\")\n",
    "file2.write(f\"<p>Volume of Lesions: {lesions_vol}</p>\\n\")\n",
    "file2.write(\"</body>\")\n",
    "file2.write(\"</head>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the above code block was successful in running, then it means that a test of BIANCA was fun successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please Ignore the Trial Working below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q flask==0.12.2\n",
    "# !pip install -q flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pyngrok\n",
    "# !ngrok authtoken 22FhSmeHSUGwYAfPE1MOegxwS9Z_2xW7bjhtziVjrDS3tC7nT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from Jinja2) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing-2022-04-25/templates\n"
     ]
    }
   ],
   "source": [
    "# folder_name = f\"{directory_name}/templates\"\n",
    "# print(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-73-c1f28239281e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-c1f28239281e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    <!DOCTYPE html>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ADD HTML CODE HERE\n",
    "%%writefile templates/Portfolio.html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\" dir=\"ltr\">\n",
    "<head>\n",
    "  <title>{{name}}'s Portfolio Website</title>\n",
    "  <style>\n",
    "    table{\n",
    "      border:3px solid black;\n",
    "    }\n",
    "    th, td {\n",
    "      border:1px solid black;\n",
    "    }\n",
    "    .table{\n",
    "      width: 100%;\n",
    "      text-align: center;\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "    <h1>Welcome to my website!</h1>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, render_template, request\n",
    "# from flask_ngrok import run_with_ngrok\n",
    " \n",
    "# app = Flask(__name__, template_folder = '/content/templates')\n",
    "# run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "# @app.route(\"/\")\n",
    "# def home():\n",
    "#     your_name = \"Zunair Viqar\"\n",
    "#     your_occupation = \"Junior at NYU\"\n",
    "#     your_description = \"My declared major is in Computer Science with minors in Applied Mathematics and Interactive Media.\"\n",
    "#     your_githubUrl = \"https://github.com/Zunairviqar\"\n",
    "#     your_favImgDescription = \"Here is my favorite picture that I can relate to in Exam Season\"\n",
    "#     projects_list = [\n",
    "#       {\"project\": \"Graphical User Interface\", \"purpose\" : \"For Automated Detection of Lesions in Multiple Sclerosis\", \"month_completed\": \"August 2021\"},\n",
    "#       {\"project\": \"enetwa.com\", \"purpose\" : \"A website to help out my friend kickstart his e-commerce business\", \"month_completed\": \"August 2018 - May 2019\"},\n",
    "#       {\"project\": \"Slack Bot\", \"purpose\" : \"Runs daily to obtain data from Google Cloud and posts it on Slack\", \"month_completed\": \"July 2021\"}\n",
    "#     ]\n",
    "#     experiences_list = [\n",
    "#       {\"position\": \"Member\", \"institution\" : \"NYU Abu Dhabi Student Government\", \"duration\": \"January 2020 - Present\"},\n",
    "#       {\"position\": \"Student Body President\", \"institution\" : \"Nixor College\", \"duration\": \"January 2020 - Present\"},\n",
    "#       {\"position\": \"Chief Executive Officer\", \"institution\" : \"Nixor Hospital - a student run NGO\", \"duration\": \"February 2018 - August 2018\"}\n",
    "#     ]\n",
    "#     your_favImgUrl = \"https://worldwideexperience.com/wp-content/uploads/2020/06/Backup-for-original-945x385.jpg\"\n",
    "#     return render_template(\"Portfolio.html\",name=your_name, \n",
    "#                            occupation=your_occupation,\n",
    "#                            description=your_description, \n",
    "#                            githubUrl = your_githubUrl,\n",
    "#                            projects=projects_list, \n",
    "#                            experiences = experiences_list,\n",
    "#                            favImgDescription = your_favImgDescription,\n",
    "#                            favImgUrl = your_favImgUrl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
