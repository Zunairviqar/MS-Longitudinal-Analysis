{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal Analysis of MRI Scans of Multiple Sclerosis Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to document the process to train BIANCA and LOCATE, and to have a script that allows re-doing the process automatically without having to manually sort, rename or adjust any files.\n",
    "\n",
    "##### This Jupyter Notebook is accompanied with a Graphical User Interface that simply allows the utilization of the models trained in this notebook in the form of an interactive application. Please feel free to use that!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to the code part, it is essential to understand the steps that will be required for training BIANCA, and then LOCATE. We will be starting off with very little manual data renaming, which will be used to train BIANCA, and then all of it will be used for LOCATE\n",
    "\n",
    "Following the training practical [https://open.win.ox.ac.uk/pages/fslcourse/practicals/seg_struc/index.html#bianca], we will be needing the following files for each subject, regardless of how many subjects there are:\n",
    "- Flair Brain Image\n",
    "- Flair Brian Lesion Mask \n",
    "\n",
    "The terms 'Optional' are used so that, in the case of good quality Brain Images, we can use the additional files as parameters to BIANCA to support the Model in its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we will be needing the **Flair Brain Image**, **Flair Brain Lesion Mask**, and the **T1 Brain Image** (Optional) for each subject. \n",
    "Once we have those, we can proceed and extract the remaining by registration and resampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another condition to ensure the proper functioning of the code blocks in this Jupyter Notebook is to have a folder that contains the names of the **Flair Brain Image**, **Flair Brain Lesion Mask**, and the **T1 Brain Image** with the following convention and structure:\n",
    "\n",
    "**ms_0xx_tpy_z.nii.gz**\n",
    "(x = subject number, y = timepoint, z = file name)\n",
    "- As an example:\n",
    "    - ms_002_tp1_flair_brain.nii.gz \n",
    "        - (having 'flair_brain' in the name is necessary)\n",
    "    - ms_002_tp1_lesion_mask.nii.gz \n",
    "        - (having 'mask' in the name is necessary)\n",
    "    - ms_002_tp1_T1_brain.nii.gz    \n",
    "        - (having 'T1' in the name is necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of a folder I created for the test run is as follows:\n",
    "\n",
    "\n",
    "<img src=\"notebook_images/file_structure.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Resampling all Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that BIANCA requires all the **Flair Brain Image(s)** to be in the same dimensions, therefore we will figure out the most common/ occuring dimensions and will then resample all other images to be of that very dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dimensions for all the flair brain Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we get the folder path where all the images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory(type):\n",
    "    from tkinter import Tk, filedialog\n",
    "\n",
    "    root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "    root.withdraw() # Hides small tkinter window.\n",
    "    root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "    \n",
    "    if(type == \"folder\"):\n",
    "        open_file = filedialog.askdirectory() # Returns opened path as str\n",
    "    \n",
    "    elif(type==\"file\"):\n",
    "        open_file = filedialog.askopenfilename() # Returns opened path as str\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid File Type\")\n",
    "        return 0\n",
    "\n",
    "    return(open_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data\n"
     ]
    }
   ],
   "source": [
    "open_file = get_directory(\"folder\")\n",
    "print(open_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring the correct folder is selected by printing out the names of all the files within the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ms_010_tp1_flair_brain.nii.gz', 'ms_005_tp1_t1_to_flair.nii.gz', 'ms_008_tp1_lesion_mask.nii.gz', 'ms_002_tp1_lesion_mask.nii.gz', 'ms_008_tp1_t1_to_flair.nii.gz', 'ms_002_tp1_t1_to_flair.nii.gz', 'ms_001_tp1_t1_to_flair.nii.gz', '.DS_Store', 'ms_006_tp1_lesion_mask.nii.gz', 'ms_006_tp1_t1_to_flair.nii.gz', 'ms_001_tp1_lesion_mask.nii.gz', 'ms_007_tp1_t1_to_flair.nii.gz', 'ms_007_tp1_lesion_mask.nii.gz', 'ms_004_tp1_lesion_mask.nii.gz', 'ms_003_tp1_t1_to_flair.nii.gz', 'ms_009_tp1_t1_to_flair.nii.gz', 'ms_003_tp1_lesion_mask.nii.gz', 'ms_009_tp1_lesion_mask.nii.gz', 'ms_004_tp1_t1_to_flair.nii.gz', 'Training-2023-04-02', 'ms_003_tp1_flair_brain.nii.gz', 'ms_009_tp1_flair_brain.nii.gz', 'ms_004_tp1_flair_brain.nii.gz', 'ms_005_tp1_lesion_mask.nii.gz.nii.gz', 'ms_007_tp1_flair_brain.nii.gz', 'ms_001_tp1_flair_brain.nii.gz', 'ms_006_tp1_flair_brain.nii.gz', 'Training-2023-02-19', 'ms_010_tp1_t1_to_flair.nii.gz', 'ms_005_tp1_flair_brain.nii.gz', 'ms_008_tp1_flair_brain.nii.gz', 'ms_002_tp1_flair_brain.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir(open_file) # returns list\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second, we create 3 different lists, and then store the files for the Flair Brain, Lesion Mask and T1 Brain images respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = []\n",
    "masks = []\n",
    "t1s = []\n",
    "\n",
    "for file in files:\n",
    "#     print(file)\n",
    "    if 'flair_brain' in file:\n",
    "        flairs.append(file)\n",
    "    elif 'mask' in file:\n",
    "        masks.append(file)\n",
    "    elif 'T1' in file:\n",
    "        t1s.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Flair Brain Images are:\n",
      "['ms_010_tp1_flair_brain.nii.gz', 'ms_003_tp1_flair_brain.nii.gz', 'ms_009_tp1_flair_brain.nii.gz', 'ms_004_tp1_flair_brain.nii.gz', 'ms_007_tp1_flair_brain.nii.gz', 'ms_001_tp1_flair_brain.nii.gz', 'ms_006_tp1_flair_brain.nii.gz', 'ms_005_tp1_flair_brain.nii.gz', 'ms_008_tp1_flair_brain.nii.gz', 'ms_002_tp1_flair_brain.nii.gz']\n",
      "\n",
      "All the Lesion Mask Images are:\n",
      "['ms_008_tp1_lesion_mask.nii.gz', 'ms_002_tp1_lesion_mask.nii.gz', 'ms_006_tp1_lesion_mask.nii.gz', 'ms_001_tp1_lesion_mask.nii.gz', 'ms_007_tp1_lesion_mask.nii.gz', 'ms_004_tp1_lesion_mask.nii.gz', 'ms_003_tp1_lesion_mask.nii.gz', 'ms_009_tp1_lesion_mask.nii.gz', 'ms_005_tp1_lesion_mask.nii.gz.nii.gz']\n",
      "\n",
      "All the T1 Brain Images are:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"All the Flair Brain Images are:\")\n",
    "print(flairs)\n",
    "print()\n",
    "print(\"All the Lesion Mask Images are:\")\n",
    "print(masks)\n",
    "print()\n",
    "print(\"All the T1 Brain Images are:\")\n",
    "print(t1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the most frequently occuring dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(terminal_command):\n",
    "    p = os.popen(terminal_command)\n",
    "    if p:\n",
    "        return p.read()\n",
    "    else:\n",
    "        return \"Command Invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:  ms_010_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_003_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_009_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_004_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_007_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_001_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_006_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_005_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_008_tp1_flair_brain.nii.gz\n",
      "256 256 35\n",
      "Dimensions of:  ms_002_tp1_flair_brain.nii.gz\n",
      "256 256 35\n"
     ]
    }
   ],
   "source": [
    "dimensions = []\n",
    "directory_1 = open_file.replace(' ', '\\ ')\n",
    "\n",
    "def check_dimensions(file_name, printvals):\n",
    "        output = run_command(f\"cd {directory_1} && fslinfo {file_name}\")\n",
    "        output = output.replace(\"\\t\", \"\\n\")\n",
    "        file_info = output.split(\"\\n\")\n",
    "        while '' in file_info:\n",
    "            file_info.remove('')\n",
    "        #print(file_info)\n",
    "        dim1 = file_info[3]\n",
    "        dim2 = file_info[5]\n",
    "        dim3 = file_info[7]\n",
    "        if printvals== True:\n",
    "            print(\"Dimensions of: \", file_name)\n",
    "            print(dim1,dim2,dim3)\n",
    "        return(dim1,dim2,dim3)\n",
    "\n",
    "for i in range(len(flairs)):\n",
    "    dimensions.append(check_dimensions(flairs[i], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Most Frequently Occuring Dimension is: \n",
      "256 x 256 x 35\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    " \n",
    "most_freq = most_frequent(dimensions)\n",
    "print(\"The Most Frequently Occuring Dimension is: \")\n",
    "print(most_freq[0],\"x\", most_freq[1],\"x\", most_freq[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking an Image with the most frequently occuring dimension for reference purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index for the most frequently occuring dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = dimensions.index(most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the corresponding Value from the *flairs* list for the corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_010_tp1_flair_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "ref_img = flairs[ind]\n",
    "print(ref_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subdirectory 'Training-{DATE}' to store all the resampled files, which shall be used for training purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(folder_path, directory_name):\n",
    "    path = os.path.join(folder_path, directory_name)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "directory_name = 'Training-' + str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory(open_file, directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within the subdirectory, we create multiple subdirectories for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_010_tp1\n",
      "ms_003_tp1\n",
      "ms_009_tp1\n",
      "ms_004_tp1\n",
      "ms_007_tp1\n",
      "ms_001_tp1\n",
      "ms_006_tp1\n",
      "ms_005_tp1\n",
      "ms_008_tp1\n",
      "ms_002_tp1\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    print(\"_\".join(file.split('_')[0:3]))\n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    create_directory(open_file + '/' + directory_name, folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we should essentially have a directory structure like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/new_folders.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the reference Image, we iterate through all the flair brain images with different dimensions and resample them to be in the same dimensions, and then store them into their respective subdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do the same for the corresponding Lesion Masks to those Flair Brain Images since they should be resampled into the same dimensions as their corresponding flairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, out of all the subjects, one of the Subjects will be solely for testing purposes and will not have an existing flair lesion mask. Therefore, since it can be any, we will ask the user for the subject number and timepoint for the test subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the Test Subject as ms_0xx_tpx (example: ms_003_tp1) ms_010_tp1\n"
     ]
    }
   ],
   "source": [
    "training_folder = input(\"Please enter the Test Subject as ms_0xx_tpx (example: ms_003_tp1) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Subject is:  ms_010_tp1\n"
     ]
    }
   ],
   "source": [
    "training_subject_bianca = training_folder\n",
    "print(\"The Test Subject is: \", training_subject_bianca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPYING...\n",
      "Copying the file: ms_010_tp1_flair_brain.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_003_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_003_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_003_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_009_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_009_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_009_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_004_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_004_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_004_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_007_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_007_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_007_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_001_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_001_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_001_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_006_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_006_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_006_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_005_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_005_tp1_lesion_mask.nii.gz.nii.gz\n",
      "Copying the file: ms_005_tp1_lesion_mask.nii.gz.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_008_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_008_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_008_tp1_lesion_mask.nii.gz\n",
      "COPYING...\n",
      "Copying the file: ms_002_tp1_flair_brain.nii.gz\n",
      "Mask to be Copied:  ms_002_tp1_lesion_mask.nii.gz\n",
      "Copying the file: ms_002_tp1_lesion_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # For all the images that have a dimension other than the most occuring dimension\n",
    "    if check_dimensions(file, False) != check_dimensions(ref_img, False):\n",
    "        print(\"RESAMPLING....\")\n",
    "        print(\"FILE TO BE RESAMPLED: \", file)\n",
    "        print()\n",
    "                \n",
    "        # Resampling the Flair Brain Image\n",
    "        output = run_command(f\"cd {directory_1} && flirt -in {file} -ref {ref_img} -out {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz -omat {directory_name}/{folder_name}/resampling.mat -interp nearestneighbour -dof 6\")\n",
    "        \n",
    "        if(folder_name != training_folder):\n",
    "            \n",
    "            # FIND THE LESION MASK FOR THE SAME FILE\n",
    "            for mask in masks:\n",
    "                if (folder_name in mask):\n",
    "                    print(\"Mask to be Resampled: \",mask)\n",
    "                    mask_file = mask\n",
    "                    break\n",
    "\n",
    "\n",
    "            # Resampling the Flair Lesion Mask\n",
    "            output = run_command(f\"cd {directory_1} && flirt -in {mask_file} -ref {ref_img} -out {directory_name}/{folder_name}/{folder_name}_flair_lesion_mask.nii.gz -applyxfm -init {directory_name}/{folder_name}/resampling.mat -interp nearestneighbour -dof 6\")\n",
    "\n",
    "        # Deleting the Resampling.mat file since it is of no use to us   \n",
    "        output = run_command(f\"cd {directory_1} && rm {directory_name}/{folder_name}/resampling.mat\")\n",
    "    \n",
    "    # In the case that the file does not need to be resampled, we simply just copy/paste it into the specific training directory     \n",
    "    else:    \n",
    "        print(\"COPYING...\")\n",
    "        print(\"Copying the file:\", file)\n",
    "        # Copying the Flair Brain Images\n",
    "        output = run_command(f\"cd {directory_1} && cp {file} {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz\")\n",
    "        \n",
    "        if(folder_name != training_folder):\n",
    "            \n",
    "            # FIND THE LESION MASK FOR THE SAME FILE\n",
    "            for mask in masks:\n",
    "                if (folder_name in mask):\n",
    "                    print(\"Mask to be Copied: \",mask)\n",
    "                    mask_file = mask\n",
    "                    break\n",
    "\n",
    "            print(\"Copying the file:\", mask_file)\n",
    "            # Copying the Flair Lesion Mask\n",
    "            output = run_command(f\"cd {directory_1} && cp {mask_file} {directory_name}/{folder_name}/{folder_name}_flair_lesion_mask.nii.gz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Step: Flair Brain to MNI for .mat (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This step is an Optional step, and the output is only used when the Flair Brain Images are of very good quality. While we will proceed with the step, we may not be using its results in the training and testing of BIANCA).\n",
    "\n",
    "Now that we have all the images over the same dimensions, we can move forward with the step of extracting the .mat\n",
    "file needed to train BIANCA by registering the flair brain image over the sample MNI Image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a pre-requisite to this step, we need the MNI Space reference file in order to register the resampled flair brains to MNI Space and retrieve the .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/MNI_file.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the location of this file is not fixed, we can go ahead and select the file path for the MNI Space file by running the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "mni_directory = get_directory(\"file\")\n",
    "print(mni_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we actually move forward and apply the registration command to transform the Flair Brain Image to the MNI Space and extract the .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being Registered is:  ms_010_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_003_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_009_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_004_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_007_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_001_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_006_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_005_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_008_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_002_tp1_flair_brain.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # Registering the FLAIR Brain Image to MNI Space\n",
    "    print(f\"File being Registered is:  {folder_name}_flair_brain.nii.gz\")\n",
    "    output = run_command(f\"cd {directory_1}/{directory_name} && flirt -in {folder_name}/{folder_name}_flair_brain.nii.gz -ref {mni_directory} -out {folder_name}/{folder_name}_flair_brain_to_MNI.nii.gz -omat {folder_name}/{folder_name}_flair_brain_to_MNI.mat -bins 256 -cost normcorr -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -dof 7 -interp nearestneighbour\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Step: T1 Brain to Flair Brain (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(As with the Regsitration to MNI Space, this is again an Optional Step and the output is only considered for good quality images)\n",
    "\n",
    "Following a similar approach to the Second Step, this time we will use the T1 Brain Image and then register it onto the Flair Brain images across all the subjects. These T1 Images (stored in the master directory, will actually be registered to the resampled version of the Flair Brain Images (stored in their respective directories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration, the grey highlighted file ***'ms_003_tp1_T1_brain.nii.gz'*** in the left most column will be registered to the blue highlighted file ***'ms_003_tp1_flair_brain.nii.gz'*** in the right most column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/t1_flair.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we actually move forward and apply the registration command to transform the T1 Brain Image to the Resampled Flair Brain Image and obtain the T1 Brain to Flair Brain Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in t1s:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # Registering the T1 Image to Flair Image\n",
    "    print(\"Registering the file: \",file)\n",
    "    output = run_command(f\"cd {directory_1} && flirt -in {file} -ref {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz -out {directory_name}/{folder_name}/{folder_name}_t1_to_flair.nii.gz -omat {directory_name}/{folder_name}/{folder_name}_t1_to_flair.mat -bins 256 -cost normcorr -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -dof 7 -interp nearestneighbour\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far, we should have the following files and a similar file structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/all_file_structure.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Step: Generating the Masterfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the files, we will be creating a masterfile.txt which includes all the four files that were highlighted on the previous screenshot, or only the Flair Brain & Lesion Mask, whichever is suitable for us.\n",
    "\n",
    "For the purposes of our use, we will go ahead with the Flair Brain & Lesion masks only, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_003_tp1/ms_003_tp1_flair_brain.nii.gz ms_003_tp1/ms_003_tp1_flair_lesion_mask.nii.gz\n",
      "ms_009_tp1/ms_009_tp1_flair_brain.nii.gz ms_009_tp1/ms_009_tp1_flair_lesion_mask.nii.gz\n",
      "ms_004_tp1/ms_004_tp1_flair_brain.nii.gz ms_004_tp1/ms_004_tp1_flair_lesion_mask.nii.gz\n",
      "ms_007_tp1/ms_007_tp1_flair_brain.nii.gz ms_007_tp1/ms_007_tp1_flair_lesion_mask.nii.gz\n",
      "ms_001_tp1/ms_001_tp1_flair_brain.nii.gz ms_001_tp1/ms_001_tp1_flair_lesion_mask.nii.gz\n",
      "ms_006_tp1/ms_006_tp1_flair_brain.nii.gz ms_006_tp1/ms_006_tp1_flair_lesion_mask.nii.gz\n",
      "ms_005_tp1/ms_005_tp1_flair_brain.nii.gz ms_005_tp1/ms_005_tp1_flair_lesion_mask.nii.gz\n",
      "ms_008_tp1/ms_008_tp1_flair_brain.nii.gz ms_008_tp1/ms_008_tp1_flair_lesion_mask.nii.gz\n",
      "ms_002_tp1/ms_002_tp1_flair_brain.nii.gz ms_002_tp1/ms_002_tp1_flair_lesion_mask.nii.gz\n",
      "ms_010_tp1/ms_010_tp1_flair_brain.nii.gz ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "f = open(f\"{open_file}/{directory_name}/masterfile.txt\", \"w\")\n",
    "\n",
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name != training_folder):\n",
    "\n",
    "        print(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "        f.write(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_flair_lesion_mask.nii.gz \\n\")\n",
    "        \n",
    "        # the code below could have been used for making use of the other two files, particularly the MNI Space Registration and the T1 to Flair Registration.\n",
    "        # f.write(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_t1_to_flair.nii.gz {folder_name}/{folder_name}_flair_brain_to_MNI.mat {folder_name}/{folder_name}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "\n",
    "# Writing the test subject at the very end to correspond with the Training Command (in the upcoming code blocks)\n",
    "print(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "f.write(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "# the code below could have been used for making use of the other two files, particularly the MNI Space Registration and the T1 to Flair Registration.\n",
    "# f.write(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_t1_to_flair.nii.gz {training_folder}/{training_folder}_flair_brain_to_MNI.mat {training_folder}/{training_folder}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The file should look similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject should have their individual entry on each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/masterfile_img.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Step: Training BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data to Train BIANCA, and it is linked in the Masterfile, we will move forward and train BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below runs the Training Command for Bianca, and tests it on the very last image. There are numerous other query parameters that could be passed, which are detailed further here:\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA/Userguide#BIANCA_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 &&     bianca --singlefile=masterfile.txt --trainingnums=1,2,3,4,5,6,7,8,9,10 --labelfeaturenum=2     --querysubjectnum=10 --brainmaskfeaturenum=1     --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o ms_010_tp1/bianca_output     --saveclassifierdata=mytraining -v\n",
      "Number of modalities = 2 , number of possible training subjects = 10\n",
      "Files are: label file list = , data file list = ['masterfile.txt']\n",
      "Number of training points = 2000, mode = ['npoints', 'noborder']\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data\n",
      " ... reading label ms_003_tp1/ms_003_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_003_tp1/ms_003_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_009_tp1/ms_009_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_009_tp1/ms_009_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_004_tp1/ms_004_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_004_tp1/ms_004_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_007_tp1/ms_007_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_007_tp1/ms_007_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_001_tp1/ms_001_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_001_tp1/ms_001_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_006_tp1/ms_006_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_006_tp1/ms_006_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_005_tp1/ms_005_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_005_tp1/ms_005_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_008_tp1/ms_008_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_008_tp1/ms_008_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_002_tp1/ms_002_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_002_tp1/ms_002_tp1_flair_brain.nii.gz\n",
      "Training data is size (108000, 1)\n",
      "Saving training data of size (108000, 1)\n",
      "Saving training data as  mytraining\n",
      "Loading query data\n",
      "  Query file list = ['ms_010_tp1/ms_010_tp1_flair_brain.nii.gz', 'ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz']\n",
      " ... reading label ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz\n",
      " ... no label found - ignoring\n",
      " ... reading image ms_010_tp1/ms_010_tp1_flair_brain.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_nums = []\n",
    "for i in range(len(flairs)):\n",
    "    training_nums.append(i)\n",
    "\n",
    "t_nums = \",\".join([str(elem+1) for elem in training_nums])\n",
    "print(t_nums)\n",
    "\n",
    "print(\n",
    "    f\"cd {directory_1}/{directory_name} && \\\n",
    "    bianca --singlefile=masterfile.txt --trainingnums={t_nums} --labelfeaturenum=2 \\\n",
    "    --querysubjectnum={len(training_nums)} --brainmaskfeaturenum=1 \\\n",
    "    --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o {training_folder}/bianca_output \\\n",
    "    --saveclassifierdata=mytraining -v\")\n",
    "\n",
    "# The code block commented below could be used for making use of all the 4 files that we generated\n",
    "# output = run_command(f\"cd {directory_1}/{directory_name} && \\\n",
    "#     bianca --singlefile=masterfile.txt --trainingnums={t_nums} --labelfeaturenum=4 \\\n",
    "#     --querysubjectnum={len(training_nums)} --brainmaskfeaturenum=1 --featuresubset=1,2 --matfeaturenum=3 \\\n",
    "#     --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o {training_folder}/bianca_output \\\n",
    "#     --saveclassifierdata=mytraining -v\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the above code block ran successfully, we have successfully ran and stored the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, as a final step, we will move ahead and produce a file which contains some basic information, or metadata in proper terminology, from the training so that it could be used when we are testing using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information we need to store is the reference dimension and the reference image with that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('256', '256', '35')\n"
     ]
    }
   ],
   "source": [
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_file = open(f\"{training_directory}/metadata.txt\", \"w\")\n",
    "storage_file.write(f\"{most_freq[0]},{most_freq[1]},{most_freq[2]}\\n\")\n",
    "storage_file.write(f\"{ref_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is needed to build on top of our BIANCA output. The purpose that it would serve is to allow for a dynamic way of applying a threshold, rather than a Binary method of doing so - which would have led to discrepancies in our results.\n",
    "\n",
    "https://git.fmrib.ox.ac.uk/vaanathi/LOCATE-BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCATE is a supervised method and hence requires data for training. However, since we already have labelled data with which we trained BIANCA, we can simply proceed and process that data further to train LOCATE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Creating the Directory & Sub Directories for Training/ Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02\n"
     ]
    }
   ],
   "source": [
    "# training_directory_name=\"Training-2023-02-19\" Commented because of kernel stoppage\n",
    "# open_file = \"/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall 2023/Sample_Prepared_Data\"\n",
    "training_directory = open_file + '/' + directory_name\n",
    "print(training_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "directory_name = 'LOCATE_Training-' + str(today)\n",
    "\n",
    "# Creating the Parent Directory\n",
    "create_directory(training_directory, directory_name)\n",
    "\n",
    "locate_training_directory = training_directory + \"/\"+directory_name\n",
    "\n",
    "# Creating the Training Sub-Directory\n",
    "create_directory(locate_training_directory, \"Training_imgs_directory\")\n",
    "\n",
    "# Creating the Training Sub-Directory\n",
    "create_directory(locate_training_directory, \"Test_imgs_directory\")\n",
    "\n",
    "# Creating the Sub-Directory for any other processing required\n",
    "create_directory(locate_training_directory, \"Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Preparing the Training Data for LOCATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain results from LOCATE, we need to prepare some files which make use of the data that we already have present, but some additional pre processing on it to generate intermediary files that will be used to train LOCATE.\n",
    "\n",
    "The required images are obtained in the next few blocks of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The base image modality used in BIANCA\n",
    "In the format: '(subject_name)-feature-(base_modality_name).nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in flairs:\n",
    "\n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && cp {folder_name}/{file} {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be skipping File No.2 since we are not making use of T1 Images or the MNI Space Registered Images:\n",
    "\n",
    "_2. Any other additional images that were used as intensity features in BIANCA (--featuresubset) (optional)\n",
    "<subject_name>_feature_<modality_name>.nii.gz (eg. <subject_name>_feature_T1.nii.gz, please note that it is mandatory to add feature in the filename before the modality name for it to be considered as a feature)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lesion Manual mask (for training subjects only): binary mask (values of 0 and 1) indicating lesion voxels, based on manual segmentation \n",
    "As we had manually labelled lesion masks for the training of BIANCA, we will be simply using them in this step:\n",
    "\n",
    "In the format: (subject_name)_manualmask.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = \"Training_imgs_directory\"\n",
    "for mask in masks:\n",
    "\n",
    "    folder_name = \"_\".join(mask.split('_')[0:3])\n",
    "    folder_name_fixed = \"-\".join(mask.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        output = run_command(f\"cd {training_directory} && cp {folder_name}/{folder_name}_flair_lesion_mask.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_manualmask.nii.gz\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following files can be obtained together:\n",
    "\n",
    "### 4. Ventricle distance map: image where each voxel intensity represents the distance from ventricles within the brain mask\n",
    "\n",
    "### 6. Brain mask: binary mask obtained from FSL-BET or any other method\n",
    "\n",
    "### 7. BIANCA mask: binary mask, as obtained from make_bianca_mask (white matter mask excluding sub-cortical regions) - If you are not using BIANCA mask in your analysis, make a copy of the brain mask and rename it as BIANCA mask.\n",
    "\n",
    "In the formats:\n",
    "- (subject_name)_ventdistmap.nii.gz\n",
    "- (subject_name)_brainmask.nii.gz\n",
    "- (subject_name)_biancamask.nii.gz\n",
    "\n",
    "With the ultimate goal to obtain the ventdistmap, we will be obtaining the brain and bianca masks as intermediary files. The ventdistmap can be calculated using the FSL tool distancemap – see the wiki for more details. Example call: \n",
    "\n",
    "distancemap -i\n",
    "<ventricle_mask_image_in_FLAIR_space> -m <brain_mask_in_FLAIR_space> -o\n",
    "<subject_name>_ventdistmap.nii.gz\n",
    " <subject_name>_ventdistmap.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this, we first run FSL Fast to get the CSF pve file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2023-04-02/Processing LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/_pve_0.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    print(f\"cd {training_directory} && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {directory_name}/Processing {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "    print()\n",
    "    print(f\"cd {training_directory} && cp {directory_name}/Processing/_pve_0.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")\n",
    "    print()\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {directory_name}/Processing/ {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "    print(output)  \n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && cp {directory_name}/Processing/_pve_0.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")\n",
    "    print(output) \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we need the T1 to MNI Space Image. I have referenced that here, however you can uncomment the get_directory command and select the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf\n"
     ]
    }
   ],
   "source": [
    "# Obtain the T1_@_MNI152_2mm.cnf\n",
    "# t1_2_mni = get_directory(\"folder\")\n",
    "t1_2_mni = \"/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, obtain the warp_file_MNI2structural\n",
    "\n",
    "- First Run FLIRT to obtain the affine_transf.mat file\n",
    "- Use that with FNIRT to obtain the nonlineaer_transf file\n",
    "- Use the nonlineaer_transf and calculate its inverse to get the warp_file_MNI2structural\n",
    "- Copy the output file into the respective folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_warp_file_MNI2structural.nii.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && flirt -ref /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz -in LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain.nii.gz -omat LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && fnirt --in=LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain.nii.gz --aff=LOCATE_Training-2023-04-02/Processing/my_affine_transf.mat --cout=LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf --config=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf --lambda=400,200,150,75,60,45\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && invwarp -w LOCATE_Training-2023-04-02/Processing/my_nonlinear_transf -o LOCATE_Training-2023-04-02/Processing/invwarpvol_new -r LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && cp LOCATE_Training-2023-04-02/Processing/invwarpvol_new.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    print(f\"cd {training_directory} && flirt -ref {mni_directory} -in {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz -omat {directory_name}/Processing/my_affine_transf.mat\")\n",
    "    print(f\"cd {training_directory} && fnirt --in={directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz --aff={directory_name}/Processing/my_affine_transf.mat --cout={directory_name}/Processing/my_nonlinear_transf --config={t1_2_mni} --lambda=400,200,150,75,60,45\")\n",
    "    print(f\"cd {training_directory} && invwarp -w {directory_name}/Processing/my_nonlinear_transf -o {directory_name}/Processing/invwarpvol_new -r {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "    print(f\"cd {training_directory} && cp {directory_name}/Processing/invwarpvol_new.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz\")\n",
    "\n",
    "    output = run_command(f\"cd {training_directory} && flirt -ref {mni_directory} -in {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz -omat {directory_name}/Processing/my_affine_transf.mat\")\n",
    "    print(output) \n",
    "    output = run_command(f\"cd {training_directory} && fnirt --in={directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz --aff={directory_name}/Processing/my_affine_transf.mat --cout={directory_name}/Processing/my_nonlinear_transf --config={t1_2_mni} --lambda=400,200,150,75,60,45\")\n",
    "    print(output) \n",
    "    output = run_command(f\"cd {training_directory} && invwarp -w {directory_name}/Processing/my_nonlinear_transf -o {directory_name}/Processing/invwarpvol_new -r {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz\")\n",
    "    print(output) \n",
    "    output = run_command(f\"cd {training_directory} && cp {directory_name}/Processing/invwarpvol_new.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz\")\n",
    "    print(output) \n",
    "\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we simply run the make_bianca_mask and the distancemap commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_ventdistmap.nii.gz\n",
      "generating ms-010-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_ventdistmap.nii.gz\n",
      "generating ms-003-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "Skipping ms-009\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_ventdistmap.nii.gz\n",
      "generating ms-004-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_ventdistmap.nii.gz\n",
      "generating ms-007-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_ventdistmap.nii.gz\n",
      "generating ms-001-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_ventdistmap.nii.gz\n",
      "generating ms-006-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_ventdistmap.nii.gz\n",
      "generating ms-005-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_ventdistmap.nii.gz\n",
      "generating ms-008-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && make_bianca_mask LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_csf_pve.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_warp_file_MNI2structural.nii.gz 0\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && distancemap -i LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_ventmask.nii.gz -m LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain_mask.nii.gz -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_ventdistmap.nii.gz\n",
      "generating ms-002-tp1_feature_flair_brain_mask.nii.gz\n",
      "creating ventricles mask\n",
      "creating WM mask\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    print(f\"cd {training_directory} && make_bianca_mask {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz 0\")\n",
    "    # make_bianca_mask ms-009-tp1_feature_FLAIR.nii.gz ms-009-tp1_csf_pve.nii.gz ms-009-tp1_warp_file_MNI2structural.nii.gz 0\n",
    "    \n",
    "    print(f\"cd {training_directory} && distancemap -i {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_ventmask.nii.gz -m {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_mask.nii.gz -o {directory_name}/{training_folder}/{folder_name_fixed}_ventdistmap.nii.gz\")\n",
    "    # distancemap -i ms-009-tp1_feature_FLAIR_ventmask.nii.gz -m ms-009-tp1_brainmask.nii.gz -o ms-009-tp1_ventdistmap.nii.gz\n",
    "\n",
    "    output = run_command(f\"cd {training_directory} && make_bianca_mask {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz 0\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && distancemap -i {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_ventmask.nii.gz -m {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_mask.nii.gz -o {directory_name}/{training_folder}/{folder_name_fixed}_ventdistmap.nii.gz\")\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - We rename and move around some files to make it organized and match our naming conventions in line with LOCATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_brainmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_bianca_mask.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_biancamask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && mv LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain.nii.gz LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_brain_to_MNI152_T1_2mm.log\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_flair_ventmask.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_csf_pve.nii.gz\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && rm LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_warp_file_MNI2structural.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "\n",
    "    print(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_mask.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_brainmask.nii.gz\")\n",
    "    print(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_bianca_mask.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_biancamask.nii.gz\")\n",
    "    print(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "    print(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_to_MNI152_T1_2mm.log\")    \n",
    "    print(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_ventmask.nii.gz\")    \n",
    "    print(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")    \n",
    "    print(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz\")    \n",
    "    \n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_mask.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_brainmask.nii.gz\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_bianca_mask.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_biancamask.nii.gz\")\n",
    "    print(output)\n",
    "\n",
    "    output = run_command(f\"cd {training_directory} && mv {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_brain_to_MNI152_T1_2mm.log\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_feature_flair_ventmask.nii.gz\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")\n",
    "    print(output)\n",
    "    \n",
    "    output = run_command(f\"cd {training_directory} && rm {directory_name}/{training_folder}/{folder_name_fixed}_warp_file_MNI2structural.nii.gz\")\n",
    "    print(output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 5. BIANCA output: unthresholded lesion probability map (LPM) obtained from BIANCA\n",
    "In the format:\n",
    "- (subject_name)_BIANCA_LPM.nii.gz\n",
    "\n",
    "From the above training of BIANCA, we obtained some training files which we are going to use to generate bianca outputs for all of the files that we used for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we did previously, we are going to use a similar approach to generate the BIANCA Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-010-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-010-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-010-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-010-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz']\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-003-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-003-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-003-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-009-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-009-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-009-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-004-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-004-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-004-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-007-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-007-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-007-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-001-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-001-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-001-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-001-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-006-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-006-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-006-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-005-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-005-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-005-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-005-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-008-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-008-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-008-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-002-tp1_masterfile.txt\n",
      "LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-002-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-002-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = (f\"{training_directory}\").replace(\" \", \"\\ \")\n",
    "classifier = file_path + \"/mytraining\"\n",
    "print(\"Classifier: \",classifier)\n",
    "print()\n",
    "\n",
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"-\".join(file.split('_')[0:3])\n",
    "\n",
    "    masterfile = f\"{training_directory}/{directory_name}/Processing/{folder_name}_masterfile.txt\"\n",
    "    \n",
    "    print(masterfile)\n",
    "\n",
    "    print(f\"{directory_name}/Training_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "    print()\n",
    "    file = open(masterfile, 'w')\n",
    "    file.write(f\"{directory_name}/Training_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "    file.close()\n",
    "    \n",
    "    masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "    bianca_output = f\"{folder_name}_BIANCA_LPM.nii.gz\"\n",
    "    \n",
    "    print(f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Training_imgs_directory/{bianca_output} -v\")\n",
    "    print()\n",
    "    \n",
    "    p = os.popen(\n",
    "        f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Training_imgs_directory/{bianca_output} -v\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same thing, but for the Testing Files now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_010_tp1_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-010-tp1_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Processing/ms-010-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2023-04-02/Test_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = f\"{training_subject_bianca}_tp1_flair_brain.nii.gz\"\n",
    "\n",
    "folder_name = \"-\".join(file.split('_')[0:3])\n",
    "\n",
    "masterfile = f\"{training_directory}/{directory_name}/Processing/{folder_name}_masterfile.txt\"\n",
    "print(file)\n",
    "print()\n",
    "print()\n",
    "print(f\"{directory_name}/Test_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "print()\n",
    "file = open(masterfile, 'w')\n",
    "file.write(f\"{directory_name}/Test_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "file.close()\n",
    "\n",
    "masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "bianca_output = f\"{folder_name}_BIANCA_LPM.nii.gz\"\n",
    "\n",
    "print(f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Test_imgs_directory/{bianca_output} -v\")\n",
    "print()\n",
    "\n",
    "p = os.popen(\n",
    "    f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Test_imgs_directory/{bianca_output} -v\")\n",
    "if p:x\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Running the LOCATE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the LOCATE Training File, we have to have MATLAB installed as a pre requisite. \n",
    "\n",
    "Then, we have to call the directory of the MATLAB, which, in our case, is '/Applications/MATLAB_R2022b.app/bin/matlab'. Using this, we have to call the locate training function, and pass it the trainings_imgs_directory as a parameter (we generated this directory and populated this in Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \"cd('/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02'); LOCATE_training('Training_imgs_directory');exit\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_training('Training_imgs_directory');exit\\\"\")\n",
    "\n",
    "output = run_command(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_training('Training_imgs_directory');exit\\\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: LOCATE Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have run the LOCATE Training file, we will move ahead with testing the regression model stored under LOCATE_Training_files. This will allow us to utilize this model on our prepared sets of images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \"cd('/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02'); LOCATE_testing('Test_imgs_directory', 'Training_imgs_directory');exit\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_testing('Test_imgs_directory', 'Training_imgs_directory');exit\\\"\")\n",
    "\n",
    "output = run_command(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_testing('Test_imgs_directory', 'Training_imgs_directory');exit\\\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the MetaData from our Training to add the details of the most recent LOCATE Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_file.close()\n",
    "storage_file = open(f\"{training_directory}/metadata.txt\", \"a\")\n",
    "storage_file.write(f\"\\n{locate_training_directory}\\n\")\n",
    "storage_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Storing Model for the Graphical User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there is a section of this notebook catering to the Longitduinal Analysis, we also have a Graphical User Interface which utilizes the produced models. Therefore, before we move forward with that, we will be updating/ storing the model at the appropriate location (which is the '/GUI/assets/model' directory.\n",
    "\n",
    "Moreover, when the Model, we have a lot of intermediary files that were generated which we are not going to be utilising so we will not be copying them into the 'model' directory for the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "current_directory = os.getcwd()\n",
    "path = Path(locate_training_directory)\n",
    "locate_parent_directory = path.parent.absolute()\n",
    "\n",
    "\n",
    "output = run_command(f\"cp -r {locate_training_directory}/Training_imgs_directory {current_directory}/GUI/assets/model\")\n",
    "print(output)\n",
    "\n",
    "output = run_command(f\"cp {locate_parent_directory}/masterfile.txt {current_directory}/GUI/assets/model/masterfile.txt\")\n",
    "print(output)\n",
    "\n",
    "output = run_command(f\"cp {locate_parent_directory}/metadata.txt {current_directory}/GUI/assets/model/metadata.txt\")\n",
    "print(output)\n",
    "\n",
    "output = run_command(f\"cp {locate_parent_directory}/mytraining {current_directory}/GUI/assets/model/mytraining\")\n",
    "print(output)\n",
    "\n",
    "output = run_command(f\"cp {locate_parent_directory}/mytraining_labels {current_directory}/GUI/assets/model/mytraining_labels\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the primary part of this project, the Longitudinal Analysis. \n",
    "\n",
    "So far, we have a trained model for BIANCA, and also a trained model for LOCATE. We will go ahead and utilize those for a Longitudinal Analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the LOCATE Training Directory \n",
    "This is the directory where our trained model is stored, which we will be using to obtain the segmentations. If we are running the code right after the model training, we should have our locate training directory stored. Otherwise we can simply obtain it with the get_directory command. This is to facilitate any other previously trained models as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02\n"
     ]
    }
   ],
   "source": [
    "# locate_training_directory = '/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02'\n",
    "# locate_training_directory = get_directory(\"folder\")\n",
    "print(locate_training_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory within Locate Training for Processing the Longitudinal Analysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Tests'\n",
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "create_directory(locate_training_directory, \"Longitudinal_Processing\")\n",
    "create_directory(locate_training_directory, \"Longitudinal_Tests\")\n",
    "processing_directory = locate_training_directory+\"/Longitudinal_Processing\"\n",
    "testing_directory = locate_training_directory+\"/Longitudinal_Tests\"\n",
    "print(processing_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Taking User Input for the 2 different Timepoints\n",
    "\n",
    "For our analysis, we need 2 user input timepoints which we also ask for in our Graphical User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the First Timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Longitudinal_Input/2_Sag_Timepoints/FLAIR_Sag_3mm_20180609132051_2.nii.gz\n"
     ]
    }
   ],
   "source": [
    "first_timepoint = get_directory(\"file\")\n",
    "print(first_timepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Second Timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Longitudinal_Input/2_Sag_Timepoints/FLAIR_Sag_3mm_20210907085543_2.nii.gz\n"
     ]
    }
   ],
   "source": [
    "second_timepoint = get_directory(\"file\")\n",
    "print(second_timepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Brain Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Parent Directory of where the timepoints are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Longitudinal_Input/2_Sag_Timepoints\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path = Path(second_timepoint)\n",
    "timepoints_directory = path.parent.absolute()\n",
    "print(timepoints_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_command(f\"cd {timepoints_directory} && bet {first_timepoint} {processing_directory}/tp1_brain.nii.gz\")\n",
    "output = run_command(f\"cd {timepoints_directory} && bet {second_timepoint} {processing_directory}/tp2_feature_FLAIR.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Register the Timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two timepoints input by the user are very likely to be of different dimensions, and also in different spaces, we will be resampling the First Timepoint onto the Second Timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing && flirt -in tp1_brain.nii.gz -ref tp2_feature_FLAIR.nii.gz -out tp1_feature_FLAIR.nii.gz -omat tp1_feature_FLAIR.mat -interp nearestneighbour -dof 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"cd {processing_directory} && flirt -in tp1_brain.nii.gz -ref tp2_feature_FLAIR.nii.gz -out tp1_feature_FLAIR.nii.gz -omat tp1_feature_FLAIR.mat -interp nearestneighbour -dof 6\")\n",
    "output = run_command(f\"cd {processing_directory} && flirt -in tp1_brain.nii.gz -ref tp2_feature_FLAIR.nii.gz -out tp1_feature_FLAIR.nii.gz -omat tp1_feature_FLAIR.mat -interp nearestneighbour -dof 6\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Intermediary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the registered and resampled timepoints, we will go ahead and produce the files that we did for the Testing Data previously for LOCATE. This includes generating the following files:\n",
    "\n",
    "- Brain Mask\n",
    "- BIANCA Mask\n",
    "- Ventricle Distance Map\n",
    "- BIANCA's Output of a Lesion Probability Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining all mentioned files for Timepoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = run_command(f\"cd {locate_training_directory} && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {locate_training_directory}/Longitudinal_Processing/ {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/_pve_0.nii.gz {locate_training_directory}/Longitudinal_Processing/tp1_csf_pve.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && /usr/local/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {locate_training_directory}/Longitudinal_Processing/ {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/_pve_0.nii.gz {locate_training_directory}/Longitudinal_Processing/tp2_csf_pve.nii.gz\")\n",
    "\n",
    "t1_2_mni = \"/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/T1_2_MNI152_2mm.cnf\"\n",
    "mni_directory = \"/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Datasets/MNI152_2mm_brain.nii.gz\"\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && flirt -ref {mni_directory} -in {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz -omat {locate_training_directory}/Longitudinal_Processing/my_affine_transf.mat\") \n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && fnirt --in={locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz --aff={locate_training_directory}/Longitudinal_Processing/my_affine_transf.mat --cout={locate_training_directory}/Longitudinal_Processing/my_nonlinear_transf --config={t1_2_mni} --lambda=400,200,150,75,60,45\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && invwarp -w {locate_training_directory}/Longitudinal_Processing/my_nonlinear_transf -o {locate_training_directory}/Longitudinal_Processing/invwarpvol_new -r {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz\") \n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/invwarpvol_new.nii.gz {locate_training_directory}/Longitudinal_Processing/tp1_warp_file_MNI2structural.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR_brain.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && make_bianca_mask {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz {locate_training_directory}/Longitudinal_Processing/tp1_csf_pve.nii.gz {locate_training_directory}/Longitudinal_Processing/tp1_warp_file_MNI2structural.nii.gz 0\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && distancemap -i {locate_training_directory}/Longitudinal_Processing/tp1_feature_flair_ventmask.nii.gz -m {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR_brain_mask.nii.gz -o {locate_training_directory}/Longitudinal_Processing/tp1_ventdistmap.nii.gz\")\n",
    "\n",
    "path = Path(locate_training_directory)\n",
    "locate_parent_directory = path.parent.absolute()\n",
    "\n",
    "\n",
    "masterfile = f\"{locate_training_directory}/Longitudinal_Processing/tp1_masterfile.txt\"\n",
    "print(f\"{locate_training_directory}/Longitudinal_rocessing/tp1_feature_FLAIR.nii.gz\")\n",
    "print()\n",
    "file = open(masterfile, 'w')\n",
    "file.write(f\"{locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz\")\n",
    "file.close()\n",
    "\n",
    "masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "bianca_output = \"tp1_BIANCA_LPM.nii.gz\"\n",
    "\n",
    "print(f\"cd {locate_parent_directory} && bianca --singlefile={masterfile} --loadclassifierdata={locate_parent_directory}/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o {locate_training_directory}/Longitudinal_Processing/tp1_BIANCA_LPM.nii.gz -v\")\n",
    "print()\n",
    "\n",
    "p = os.popen(\n",
    "    f\"cd {locate_parent_directory} && bianca --singlefile={masterfile} --loadclassifierdata={locate_parent_directory}/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o {locate_training_directory}/Longitudinal_Processing/tp1_BIANCA_LPM.nii.gz -v\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)\n",
    "    \n",
    "# Storing them appropriately\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR.nii.gz {testing_directory}/tp1_feature_FLAIR.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR_bianca_mask.nii.gz {testing_directory}/tp1_biancamask.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp1_feature_FLAIR_brain_mask.nii.gz {testing_directory}/tp1_brainmask.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp1_ventdistmap.nii.gz {testing_directory}/tp1_ventdistmap.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp1_BIANCA_LPM.nii.gz {testing_directory}/tp1_BIANCA_LPM.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining all mentioned files for Timepoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02 && bianca --singlefile=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_masterfile.txt --loadclassifierdata=/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/mytraining\n",
      "Training data is size (108000, 1)\n",
      "Loading query data\n",
      "  Query file list = ['/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz']\n",
      " ... reading image /Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = run_command(f\"cd {locate_training_directory} && flirt -ref {mni_directory} -in {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz -omat {locate_training_directory}/Longitudinal_Processing/my_affine_transf.mat\") \n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && fnirt --in={locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz --aff={locate_training_directory}/Longitudinal_Processing/my_affine_transf.mat --cout={locate_training_directory}/Longitudinal_Processing/my_nonlinear_transf --config={t1_2_mni} --lambda=400,200,150,75,60,45\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && invwarp -w {locate_training_directory}/Longitudinal_Processing/my_nonlinear_transf -o {locate_training_directory}/Longitudinal_Processing/invwarpvol_new -r {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\") \n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/invwarpvol_new.nii.gz {locate_training_directory}/Longitudinal_Processing/tp2_warp_file_MNI2structural.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && cp {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR_brain.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && make_bianca_mask {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz {locate_training_directory}/Longitudinal_Processing/tp2_csf_pve.nii.gz {locate_training_directory}/Longitudinal_Processing/tp2_warp_file_MNI2structural.nii.gz 0\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && distancemap -i {locate_training_directory}/Longitudinal_Processing/tp2_feature_flair_ventmask.nii.gz -m {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR_brain_mask.nii.gz -o {locate_training_directory}/Longitudinal_Processing/tp2_ventdistmap.nii.gz\")\n",
    "\n",
    "masterfile = f\"{locate_training_directory}/Longitudinal_Processing/tp2_masterfile.txt\"\n",
    "print(f\"{locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\")\n",
    "print()\n",
    "file = open(masterfile, 'w')\n",
    "file.write(f\"{locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz\")\n",
    "file.close()\n",
    "\n",
    "masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "bianca_output = \"tp2_BIANCA_LPM.nii.gz\"\n",
    "\n",
    "print(f\"cd {locate_parent_directory} && bianca --singlefile={masterfile} --loadclassifierdata={locate_parent_directory}/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o {locate_training_directory}/Longitudinal_Processing/tp2_BIANCA_LPM.nii.gz -v\")\n",
    "print()\n",
    "\n",
    "p = os.popen(\n",
    "    f\"cd {locate_parent_directory} && bianca --singlefile={masterfile} --loadclassifierdata={locate_parent_directory}/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o {locate_training_directory}/Longitudinal_Processing/tp2_BIANCA_LPM.nii.gz -v\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)\n",
    "    \n",
    "# Storing them appropriately\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR.nii.gz {testing_directory}/tp2_feature_FLAIR.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR_bianca_mask.nii.gz {testing_directory}/tp2_biancamask.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp2_feature_FLAIR_brain_mask.nii.gz {testing_directory}/tp2_brainmask.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp2_ventdistmap.nii.gz {testing_directory}/tp2_ventdistmap.nii.gz\")\n",
    "\n",
    "output = run_command(f\"cd {locate_training_directory} && mv {locate_training_directory}/Longitudinal_Processing/tp2_BIANCA_LPM.nii.gz {testing_directory}/tp2_BIANCA_LPM.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run the above blocks of code, we should have the following directory structure:\n",
    "\n",
    "- Insert Image of Training Folder with the Training Imgs and Longitudinal Tests Folders highlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run the LOCATE Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have all the files we need to run the LOCATE Model on, we will go ahead and do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \"cd('/Users/zunairviqar/Documents/GitHub/MS-Longitudinal-Analysis/Fall_2023/Sample_Prepared_Data/Training-2023-04-02/LOCATE_Training-2023-04-02'); LOCATE_testing('Longitudinal_Tests', 'Training_imgs_directory');exit\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_testing('Longitudinal_Tests', 'Training_imgs_directory');exit\\\"\")\n",
    "\n",
    "output = run_command(f\"/Applications/MATLAB_R2022b.app/bin/matlab -nodisplay -r \\\"cd('{locate_training_directory}'); LOCATE_testing('Longitudinal_Tests', 'Training_imgs_directory');exit\\\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be stored in the Longitudinal Tests directory. Particularly within the 'LOCATE_results_directory' and should be named something similar to:\n",
    "\n",
    "- ms-010-tp1_BIANCA_LOCATE_binarylesionmap.nii.gz\n",
    "- ms-010-tp2_BIANCA_LOCATE_binarylesionmap.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clean Intermediary files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not need the files in the intermediary folders, we will go ahead and remove them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(processing_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & Result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As part of our results, we have to obtain 3 different files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- New Lesions that appeared in the latest time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_command(f\"cd {testing_directory}/LOCATE_results_directory && fslmaths tp2_BIANCA_LOCATE_binarylesionmap.nii.gz -sub tp1_BIANCA_LOCATE_binarylesionmap.nii.gz {locate_training_directory}/Longitudinal_Tests/new_lesion_mask.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All Lesions that ever existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_command(f\"cd {testing_directory}/LOCATE_results_directory && fslmaths tp2_BIANCA_LOCATE_binarylesionmap.nii.gz -add tp1_BIANCA_LOCATE_binarylesionmap.nii.gz {locate_training_directory}/Longitudinal_Tests/all_lesion_mask.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lesions that were only in the previous time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_command(f\"cd {testing_directory}/LOCATE_results_directory && fslmaths tp1_BIANCA_LOCATE_binarylesionmap.nii.gz -sub tp2_BIANCA_LOCATE_binarylesionmap.nii.gz {locate_training_directory}/Longitudinal_Tests/lost_lesion_mask.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we calculate the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total WMH number for tp1_BIANCA_LOCATE_binarylesionmap.nii.gz with threshold 0 and minimum cluster size 1 is 188\n",
      " total volume for tp1_BIANCA_LOCATE_binarylesionmap.nii.gz with threshold 0 and minimum cluster size 1 is 3351.452637\n",
      "\n",
      " total WMH number for tp2_BIANCA_LOCATE_binarylesionmap.nii.gz with threshold 0 and minimum cluster size 1 is 205\n",
      " total volume for tp2_BIANCA_LOCATE_binarylesionmap.nii.gz with threshold 0 and minimum cluster size 1 is 8448.857422\n",
      "\n",
      "The Number of WMH has increased/decreased by : 17\n",
      "The Total Volume has increased/decreased by : 5097.404784999999\n"
     ]
    }
   ],
   "source": [
    "# As per https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA/Userguide#Performance_evaluation, \n",
    "# The command to run is:\n",
    "\n",
    "# bianca_cluster_stats <bianca_output_map> <threshold> <min_cluster_size> [<mask>]\n",
    "\n",
    "output = run_command(f\"cd {testing_directory}/LOCATE_results_directory && bianca_cluster_stats tp1_BIANCA_LOCATE_binarylesionmap.nii.gz 0 1\")\n",
    "print(output)\n",
    "\n",
    "num_lesions_1 = output.split(\"\\n\")[0].split(\" \")[-1]\n",
    "lesions_vol_1 = output.split(\"\\n\")[1].split(\" \")[-1]\n",
    "\n",
    "\n",
    "output = run_command(f\"cd {testing_directory}/LOCATE_results_directory && bianca_cluster_stats tp2_BIANCA_LOCATE_binarylesionmap.nii.gz 0 1\")\n",
    "print(output)\n",
    "\n",
    "num_lesions_2 = output.split(\"\\n\")[0].split(\" \")[-1]\n",
    "lesions_vol_2 = output.split(\"\\n\")[1].split(\" \")[-1]\n",
    "\n",
    "print(\"The Number of WMH has increased/decreased by :\",int(num_lesions_2)-int(num_lesions_1))\n",
    "print(\"The Total Volume has increased/decreased by :\",float(lesions_vol_2)-float(lesions_vol_1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
