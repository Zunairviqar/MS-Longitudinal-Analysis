{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BIANCA Automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to document the process to train BIANCA and to have a script that allows re-doing the process automatically without having to manually sort, rename or adjust any files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to the code part, it is essential to understand the steps that will be required for training BIANCA.\n",
    "\n",
    "Following the training practical [https://open.win.ox.ac.uk/pages/fslcourse/practicals/seg_struc/index.html#bianca], we will be needing the following files for each subject, regardless of how many subjects there are:\n",
    "- Flair Brain Image\n",
    "- Flair Brian Lesion Mask \n",
    "- T1 Brain Image (Optional)\n",
    "- Flair Brain to MNI for .mat (Optional)\n",
    "- T1 Brain to Flair Brain (Optional)\n",
    "\n",
    "The terms 'Optional' are used so that, in the case of good quality Brain Images, we can use the additional files as paramters to BIANCA to support the Model in its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we will be needing the **Flair Brain Image**, **Flair Brain Lesion Mask**, and the **T1 Brain Image** (Optional) for each subject. \n",
    "Once we have those, we can proceed and extract the remaining by registration and resampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another condition to ensure the proper functioning of the code blocks in this Jupyter Notebook is to have a folder that contains the names of the **Flair Brain Image**, **Flair Brain Lesion Mask**, and the **T1 Brain Image** with the following convention and structure:\n",
    "\n",
    "**ms_0xx_tpy_z.nii.gz**\n",
    "(x = subject number, y = timepoint, z = file name)\n",
    "- As an example:\n",
    "    - ms_002_tp1_flair_brain.nii.gz \n",
    "        - (having 'flair_brain' in the name is necessary)\n",
    "    - ms_002_tp1_lesion_mask.nii.gz \n",
    "        - (having 'mask' in the name is necessary)\n",
    "    - ms_002_tp1_T1_brain.nii.gz    \n",
    "        - (having 'T1' in the name is necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of a folder I created for the test run is as follows:\n",
    "\n",
    "\n",
    "<img src=\"notebook_images/file_structure.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Resampling all Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that BIANCA requires all the **Flair Brain Image(s)** to be in the same dimensions, therefore we will figure out the most common/ occuring dimensions and will then resample all other images to be of that very dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dimensions for all the flair brain Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we get the folder path where all the images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated BIANCA Training/All_Files\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "''\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "''\n",
    "open_file = filedialog.askdirectory() # Returns opened path as str\n",
    "print(open_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring the correct folder is selected by printing out the names of all the files within the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'ms_002_tp1_flair_brain.nii.gz', 'ms_002_tp1_flair_lesion_mask.nii.gz', 'ms_002_tp1_T1_brain.nii.gz', 'ms_003_tp1_flair_brain.nii.gz', 'ms_003_tp1_flair_lesion_mask.nii.gz', 'ms_003_tp1_T1_brain.nii.gz', 'ms_003_tp6_flair_brain.nii.gz', 'ms_003_tp6_flair_lesion_mask.nii.gz', 'ms_003_tp6_T1_brain.nii.gz', 'ms_004_tp1_flair_brain.nii.gz', 'ms_004_tp1_flair_lesion_mask.nii.gz', 'ms_004_tp1_T1_brain.nii.gz', 'ms_004_tp7_flair_brain.nii.gz', 'ms_004_tp7_flair_lesion_mask.nii.gz', 'ms_004_tp7_T1_brain.nii.gz', 'ms_006_tp1_flair_brain.nii.gz', 'ms_006_tp1_flair_lesion_mask.nii.gz', 'ms_006_tp1_T1_brain.nii.gz', 'ms_006_tp3_flair_brain.nii.gz', 'ms_006_tp3_flair_lesion_mask.nii.gz', 'ms_006_tp3_T1_brain.nii.gz', 'ms_007_tp1_flair_brain.nii.gz', 'ms_007_tp1_flair_lesion_mask.nii.gz', 'ms_007_tp1_T1_brain.nii.gz', 'ms_007_tp2_flair_brain.nii.gz', 'ms_007_tp2_flair_lesion_mask.nii.gz', 'ms_007_tp2_T1_brain.nii.gz', 'ms_008_tp1_flair_brain.nii.gz', 'ms_008_tp1_flair_lesion_mask.nii.gz', 'ms_008_tp1_T1_brain.nii.gz', 'ms_008_tp6_flair_brain.nii.gz', 'ms_008_tp6_flair_lesion_mask.nii.gz', 'ms_008_tp6_T1_brain.nii.gz', 'ms_009_tp1_flair_brain.nii.gz', 'ms_009_tp1_flair_lesion_mask.nii.gz', 'ms_009_tp1_T1_brain.nii.gz', 'ms_009_tp4_flair_brain.nii.gz', 'ms_009_tp4_flair_lesion_mask.nii.gz', 'ms_009_tp4_T1_brain.nii.gz', 'ms_010_tp1_flair_brain.nii.gz', 'ms_010_tp1_flair_lesion_mask.nii.gz', 'ms_010_tp1_T1_brain.nii.gz', 'ms_011_tp1_flair_brain.nii.gz', 'ms_011_tp1_flair_lesion_mask.nii.gz', 'ms_011_tp1_T1_brain.nii.gz', 'ms_012_tp1_flair_brain.nii.gz', 'ms_012_tp1_flair_lesion_mask.nii.gz', 'ms_012_tp1_T1_brain.nii.gz', 'ms_013_tp1_flair_brain.nii.gz', 'ms_013_tp1_T1_brain.nii.gz', 'Training-2022-05-17', 'Training-2022-09-30', 'Training-2022-11-06']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir(open_file) # returns list\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second, we create 3 different lists, and then store the files for the Flair Brain, Lesion Mask and T1 Brain images respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = []\n",
    "masks = []\n",
    "t1s = []\n",
    "\n",
    "for file in files:\n",
    "#     print(file)\n",
    "    if 'flair_brain' in file:\n",
    "        flairs.append(file)\n",
    "    elif 'mask' in file:\n",
    "        masks.append(file)\n",
    "    elif 'T1' in file:\n",
    "        t1s.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Flair Brain Images are:\n",
      "['ms_002_tp1_flair_brain.nii.gz', 'ms_003_tp1_flair_brain.nii.gz', 'ms_003_tp6_flair_brain.nii.gz', 'ms_004_tp1_flair_brain.nii.gz', 'ms_004_tp7_flair_brain.nii.gz', 'ms_006_tp1_flair_brain.nii.gz', 'ms_006_tp3_flair_brain.nii.gz', 'ms_007_tp1_flair_brain.nii.gz', 'ms_007_tp2_flair_brain.nii.gz', 'ms_008_tp1_flair_brain.nii.gz', 'ms_008_tp6_flair_brain.nii.gz', 'ms_009_tp1_flair_brain.nii.gz', 'ms_009_tp4_flair_brain.nii.gz', 'ms_010_tp1_flair_brain.nii.gz', 'ms_011_tp1_flair_brain.nii.gz', 'ms_012_tp1_flair_brain.nii.gz', 'ms_013_tp1_flair_brain.nii.gz']\n",
      "\n",
      "All the Lesion Mask Images are:\n",
      "['ms_002_tp1_flair_lesion_mask.nii.gz', 'ms_003_tp1_flair_lesion_mask.nii.gz', 'ms_003_tp6_flair_lesion_mask.nii.gz', 'ms_004_tp1_flair_lesion_mask.nii.gz', 'ms_004_tp7_flair_lesion_mask.nii.gz', 'ms_006_tp1_flair_lesion_mask.nii.gz', 'ms_006_tp3_flair_lesion_mask.nii.gz', 'ms_007_tp1_flair_lesion_mask.nii.gz', 'ms_007_tp2_flair_lesion_mask.nii.gz', 'ms_008_tp1_flair_lesion_mask.nii.gz', 'ms_008_tp6_flair_lesion_mask.nii.gz', 'ms_009_tp1_flair_lesion_mask.nii.gz', 'ms_009_tp4_flair_lesion_mask.nii.gz', 'ms_010_tp1_flair_lesion_mask.nii.gz', 'ms_011_tp1_flair_lesion_mask.nii.gz', 'ms_012_tp1_flair_lesion_mask.nii.gz']\n",
      "\n",
      "All the T1 Brain Images are:\n",
      "['ms_002_tp1_T1_brain.nii.gz', 'ms_003_tp1_T1_brain.nii.gz', 'ms_003_tp6_T1_brain.nii.gz', 'ms_004_tp1_T1_brain.nii.gz', 'ms_004_tp7_T1_brain.nii.gz', 'ms_006_tp1_T1_brain.nii.gz', 'ms_006_tp3_T1_brain.nii.gz', 'ms_007_tp1_T1_brain.nii.gz', 'ms_007_tp2_T1_brain.nii.gz', 'ms_008_tp1_T1_brain.nii.gz', 'ms_008_tp6_T1_brain.nii.gz', 'ms_009_tp1_T1_brain.nii.gz', 'ms_009_tp4_T1_brain.nii.gz', 'ms_010_tp1_T1_brain.nii.gz', 'ms_011_tp1_T1_brain.nii.gz', 'ms_012_tp1_T1_brain.nii.gz', 'ms_013_tp1_T1_brain.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(\"All the Flair Brain Images are:\")\n",
    "print(flairs)\n",
    "print()\n",
    "print(\"All the Lesion Mask Images are:\")\n",
    "print(masks)\n",
    "print()\n",
    "print(\"All the T1 Brain Images are:\")\n",
    "print(t1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the most frequently occuring dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:  ms_002_tp1_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_003_tp1_flair_brain.nii.gz\n",
      "320 320 40\n",
      "Dimensions of:  ms_003_tp6_flair_brain.nii.gz\n",
      "256 256 49\n",
      "Dimensions of:  ms_004_tp1_flair_brain.nii.gz\n",
      "256 256 25\n",
      "Dimensions of:  ms_004_tp7_flair_brain.nii.gz\n",
      "320 320 40\n",
      "Dimensions of:  ms_006_tp1_flair_brain.nii.gz\n",
      "320 320 44\n",
      "Dimensions of:  ms_006_tp3_flair_brain.nii.gz\n",
      "256 256 44\n",
      "Dimensions of:  ms_007_tp1_flair_brain.nii.gz\n",
      "256 256 43\n",
      "Dimensions of:  ms_007_tp2_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_008_tp1_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_008_tp6_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_009_tp1_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_009_tp4_flair_brain.nii.gz\n",
      "256 256 44\n",
      "Dimensions of:  ms_010_tp1_flair_brain.nii.gz\n",
      "256 256 44\n",
      "Dimensions of:  ms_011_tp1_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_012_tp1_flair_brain.nii.gz\n",
      "256 256 40\n",
      "Dimensions of:  ms_013_tp1_flair_brain.nii.gz\n",
      "256 256 46\n"
     ]
    }
   ],
   "source": [
    "dimensions = []\n",
    "directory_1 = open_file.replace(' ', '\\ ')\n",
    "\n",
    "def check_dimensions(file_name, printvals):\n",
    "    p = os.popen(\n",
    "        f\"cd {directory_1} && fslinfo {file_name}\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        #print(output)\n",
    "        output = output.replace(\"\\t\", \"\\n\")\n",
    "        file_info = output.split(\"\\n\")\n",
    "        while '' in file_info:\n",
    "            file_info.remove('')\n",
    "        #print(file_info)\n",
    "        dim1 = file_info[3]\n",
    "        dim2 = file_info[5]\n",
    "        dim3 = file_info[7]\n",
    "        if printvals== True:\n",
    "            print(\"Dimensions of: \", file_name)\n",
    "            print(dim1,dim2,dim3)\n",
    "        return(dim1,dim2,dim3)\n",
    "\n",
    "for i in range(len(flairs)):\n",
    "    dimensions.append(check_dimensions(flairs[i], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Most Frequently Occuring Dimension is: \n",
      "256 x 256 x 40\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    " \n",
    "most_freq = most_frequent(dimensions)\n",
    "print(\"The Most Frequently Occuring Dimension is: \")\n",
    "print(most_freq[0],\"x\", most_freq[1],\"x\", most_freq[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking an Image with the most frequently occuring dimension for reference purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index for the most frequently occuring dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = dimensions.index(most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the corresponding Value from the *flairs* list for the corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_002_tp1_flair_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "ref_img = flairs[ind]\n",
    "print(ref_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subdirectory 'Training-{DATE}' to store all the resampled files, which shall be used for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "directory_name = 'Training-' + str(today)\n",
    "training_directory_name = directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(open_file, directory_name)\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within the subdirectory, we create multiple subdirectories for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_002_tp1\n",
      "ms_003_tp1\n",
      "ms_003_tp6\n",
      "ms_004_tp1\n",
      "ms_004_tp7\n",
      "ms_006_tp1\n",
      "ms_006_tp3\n",
      "ms_007_tp1\n",
      "ms_007_tp2\n",
      "ms_008_tp1\n",
      "ms_008_tp6\n",
      "ms_009_tp1\n",
      "ms_009_tp4\n",
      "ms_010_tp1\n",
      "ms_011_tp1\n",
      "ms_012_tp1\n",
      "ms_013_tp1\n"
     ]
    }
   ],
   "source": [
    "folder_names = []\n",
    "\n",
    "for file in flairs:\n",
    "    print(\"_\".join(file.split('_')[0:3]))\n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    folder_names.append(folder_name)\n",
    "    \n",
    "    path = os.path.join(open_file + '/' + directory_name, folder_name)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we should essentially have a directory structure like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/new_folders.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the reference Image, we iterate through all the flair brain images with different dimensions and resample them to be in the same dimensions, and then store them into their respective subdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do the same for the corresponding Lesion Masks to those Flair Brain Images since they should be resampled into the same dimensions as their corresponding flairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, out of all the subjects, one of the Subjects will be solely for testing purposes and will not have an existing flair lesion mask. Therefore, since it can be any, we will ask the user for the subject number and timepoint for the test subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the Test Subject as ms_0xx_tpx (example: ms_003_tp1) ms_013_tp1\n"
     ]
    }
   ],
   "source": [
    "training_folder = input(\"Please enter the Test Subject as ms_0xx_tpx (example: ms_003_tp1) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Subject is:  ms_013_tp1\n"
     ]
    }
   ],
   "source": [
    "training_subject_bianca = training_folder\n",
    "print(\"The Test Subject is: \", training_subject_bianca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPYING...\n",
      "Copying the file: ms_002_tp1_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_002_tp1_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_002_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_003_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_003_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_003_tp6_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_003_tp6_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_004_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_004_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_004_tp7_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_004_tp7_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_006_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_006_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_006_tp3_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_006_tp3_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_007_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_007_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_007_tp2_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_007_tp2_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_007_tp2_flair_lesion_mask.nii.gz\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_008_tp1_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_008_tp1_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_008_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_008_tp6_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_008_tp6_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_008_tp6_flair_lesion_mask.nii.gz\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_009_tp1_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_009_tp1_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_009_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_009_tp4_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_009_tp4_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_010_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "Mask to be Resampled:  ms_010_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_011_tp1_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_011_tp1_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_011_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "COPYING...\n",
      "Copying the file: ms_012_tp1_flair_brain.nii.gz\n",
      "\n",
      "Mask to be Copied:  ms_012_tp1_flair_lesion_mask.nii.gz\n",
      "Copying the file: ms_012_tp1_flair_lesion_mask.nii.gz\n",
      "\n",
      "RESAMPLING....\n",
      "FILE TO BE RESAMPLED:  ms_013_tp1_flair_brain.nii.gz\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # For all the images that have a dimension other than the most occuring dimension\n",
    "    if check_dimensions(file, False) != check_dimensions(ref_img, False):\n",
    "        print(\"RESAMPLING....\")\n",
    "        print(\"FILE TO BE RESAMPLED: \", file)\n",
    "        print()\n",
    "                \n",
    "        # Resampling the Flair Brain Image\n",
    "        p = os.popen(\n",
    "            f\"cd {directory_1} && flirt -in {file} -ref {ref_img} -out {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz -omat {directory_name}/{folder_name}/resampling.mat -interp nearestneighbour -dof 6\")\n",
    "        if p:\n",
    "            output = p.read()\n",
    "            print(output)\n",
    "        \n",
    "        if(folder_name != training_folder):\n",
    "            \n",
    "            # FIND THE LESION MASK FOR THE SAME FILE\n",
    "            for mask in masks:\n",
    "                if (folder_name in mask):\n",
    "                    print(\"Mask to be Resampled: \",mask)\n",
    "                    mask_file = mask\n",
    "                    break\n",
    "\n",
    "\n",
    "            # Resampling the Flair Lesion Mask\n",
    "            p = os.popen(\n",
    "                f\"cd {directory_1} && flirt -in {mask_file} -ref {ref_img} -out {directory_name}/{folder_name}/{folder_name}_flair_lesion_mask.nii.gz -applyxfm -init {directory_name}/{folder_name}/resampling.mat -interp nearestneighbour -dof 6\")\n",
    "            if p:\n",
    "                output = p.read()\n",
    "                print(output)\n",
    "\n",
    "        # Deleting the Resampling.mat file since it is of no use to us        \n",
    "        p = os.popen(\n",
    "            f\"cd {directory_1} && rm {directory_name}/{folder_name}/resampling.mat\")\n",
    "        if p:\n",
    "            output = p.read()\n",
    "            print(output)\n",
    "    \n",
    "    # In the case that the file does not need to be resampled, we simply just copy/paste it into the specific training directory     \n",
    "    else:    \n",
    "        print(\"COPYING...\")\n",
    "        print(\"Copying the file:\", file)\n",
    "        # Copying the Flair Brain Images        \n",
    "        p = os.popen(\n",
    "            f\"cd {directory_1} && cp {file} {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz\")\n",
    "        if p:\n",
    "            output = p.read()\n",
    "            print(output)  \n",
    "        \n",
    "        if(folder_name != training_folder):\n",
    "            \n",
    "            # FIND THE LESION MASK FOR THE SAME FILE\n",
    "            for mask in masks:\n",
    "                if (folder_name in mask):\n",
    "                    print(\"Mask to be Copied: \",mask)\n",
    "                    mask_file = mask\n",
    "                    break\n",
    "\n",
    "            print(\"Copying the file:\", mask_file)\n",
    "            # Copying the Flair Lesion Mask        \n",
    "            p = os.popen(\n",
    "                f\"cd {directory_1} && cp {mask_file} {directory_name}/{folder_name}/{folder_name}_flair_lesion_mask.nii.gz\")\n",
    "            if p:\n",
    "                output = p.read()\n",
    "                print(output)  \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Step: Flair Brain to MNI for .mat (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This step is an Optional step, and the output is only used when the Flair Brain Images are of very good quality. While we will proceed with the step, we may not be using its results in the training and testing of BIANCA).\n",
    "\n",
    "Now that we have all the images over the same dimensions, we can move forward with the step of extracting the .mat\n",
    "file needed to train BIANCA by registering the flair brain image over the sample MNI Image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a pre-requisite to this step, we need the MNI Space reference file in order to register the resampled flair brains to MNI Space and retrieve the .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/MNI_file.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the location of this file is not fixed, we can go ahead and select the file path for the MNI Space file by running the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ms/Documents/GitHub/MS-Longitudinal-Analysis/Fall\\ 2022/BIANCA_Training_Notebook/MNI152_2mm_brain.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "''\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "''\n",
    "mni_file = filedialog.askopenfilename() # Returns opened path as str\n",
    "\n",
    "mni_directory = mni_file.replace(' ', '\\ ')\n",
    "print(mni_directory) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we actually move forward and apply the registration command to transform the Flair Brain Image to the MNI Space and extract the .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being Registered is:  ms_002_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_003_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_003_tp6_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_004_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_004_tp7_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_006_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_006_tp3_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_007_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_007_tp2_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_008_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_008_tp6_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_009_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_009_tp4_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_010_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_011_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_012_tp1_flair_brain.nii.gz\n",
      "\n",
      "File being Registered is:  ms_013_tp1_flair_brain.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # Registering the FLAIR Brain Image to MNI Space\n",
    "    print(f\"File being Registered is:  {folder_name}_flair_brain.nii.gz\")\n",
    "    p = os.popen(\n",
    "        f\"cd {directory_1}/{directory_name} && flirt -in {folder_name}/{folder_name}_flair_brain.nii.gz -ref {mni_directory} -out {folder_name}/{folder_name}_flair_brain_to_MNI.nii.gz -omat {folder_name}/{folder_name}_flair_brain_to_MNI.mat -bins 256 -cost normcorr -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -dof 7 -interp nearestneighbour\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Step: T1 Brain to Flair Brain (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(As with the Regsitration to MNI Space, this is again an Optional Step and the output is only considered for good quality images)\n",
    "\n",
    "Following a similar approach to the Second Step, this time we will use the T1 Brain Image and then register it onto the Flair Brain images across all the subjects. These T1 Images (stored in the master directory, will actually be registered to the resampled version of the Flair Brain Images (stored in their respective directories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration, the grey highlighted file ***'ms_003_tp1_T1_brain.nii.gz'*** in the left most column will be registered to the blue highlighted file ***'ms_003_tp1_flair_brain.nii.gz'*** in the right most column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/t1_flair.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we actually move forward and apply the registration command to transform the T1 Brain Image to the Resampled Flair Brain Image and obtain the T1 Brain to Flair Brain Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering the file:  ms_002_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_003_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_003_tp6_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_004_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_004_tp7_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_006_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_006_tp3_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_007_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_007_tp2_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_008_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_008_tp6_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_009_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_009_tp4_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_010_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_011_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_012_tp1_T1_brain.nii.gz\n",
      "\n",
      "Registering the file:  ms_013_tp1_T1_brain.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in t1s:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    # Registering the T1 Image to Flair Image\n",
    "    print(\"Registering the file: \",file)\n",
    "    p = os.popen(\n",
    "        f\"cd {directory_1} && flirt -in {file} -ref {directory_name}/{folder_name}/{folder_name}_flair_brain.nii.gz -out {directory_name}/{folder_name}/{folder_name}_t1_to_flair.nii.gz -omat {directory_name}/{folder_name}/{folder_name}_t1_to_flair.mat -bins 256 -cost normcorr -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -dof 7 -interp nearestneighbour\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far, we should have the following files and a similar file structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/all_file_structure.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Step: Generating the Masterfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the files, we will be creating a masterfile.txt which includes all the four files that were highlighted on the previous screenshot, or only the Flair Brain & Lesion Mask, whichever is suitable for us.\n",
    "\n",
    "For the purposes of our use, we will go ahead with the Flair Brain & Lesion masks only, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms_002_tp1/ms_002_tp1_flair_brain.nii.gz ms_002_tp1/ms_002_tp1_flair_lesion_mask.nii.gz\n",
      "ms_003_tp1/ms_003_tp1_flair_brain.nii.gz ms_003_tp1/ms_003_tp1_flair_lesion_mask.nii.gz\n",
      "ms_003_tp6/ms_003_tp6_flair_brain.nii.gz ms_003_tp6/ms_003_tp6_flair_lesion_mask.nii.gz\n",
      "ms_004_tp1/ms_004_tp1_flair_brain.nii.gz ms_004_tp1/ms_004_tp1_flair_lesion_mask.nii.gz\n",
      "ms_004_tp7/ms_004_tp7_flair_brain.nii.gz ms_004_tp7/ms_004_tp7_flair_lesion_mask.nii.gz\n",
      "ms_006_tp1/ms_006_tp1_flair_brain.nii.gz ms_006_tp1/ms_006_tp1_flair_lesion_mask.nii.gz\n",
      "ms_006_tp3/ms_006_tp3_flair_brain.nii.gz ms_006_tp3/ms_006_tp3_flair_lesion_mask.nii.gz\n",
      "ms_007_tp1/ms_007_tp1_flair_brain.nii.gz ms_007_tp1/ms_007_tp1_flair_lesion_mask.nii.gz\n",
      "ms_007_tp2/ms_007_tp2_flair_brain.nii.gz ms_007_tp2/ms_007_tp2_flair_lesion_mask.nii.gz\n",
      "ms_008_tp1/ms_008_tp1_flair_brain.nii.gz ms_008_tp1/ms_008_tp1_flair_lesion_mask.nii.gz\n",
      "ms_008_tp6/ms_008_tp6_flair_brain.nii.gz ms_008_tp6/ms_008_tp6_flair_lesion_mask.nii.gz\n",
      "ms_009_tp1/ms_009_tp1_flair_brain.nii.gz ms_009_tp1/ms_009_tp1_flair_lesion_mask.nii.gz\n",
      "ms_009_tp4/ms_009_tp4_flair_brain.nii.gz ms_009_tp4/ms_009_tp4_flair_lesion_mask.nii.gz\n",
      "ms_010_tp1/ms_010_tp1_flair_brain.nii.gz ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz\n",
      "ms_011_tp1/ms_011_tp1_flair_brain.nii.gz ms_011_tp1/ms_011_tp1_flair_lesion_mask.nii.gz\n",
      "ms_012_tp1/ms_012_tp1_flair_brain.nii.gz ms_012_tp1/ms_012_tp1_flair_lesion_mask.nii.gz\n",
      "ms_013_tp1/ms_013_tp1_flair_brain.nii.gz ms_013_tp1/ms_013_tp1_flair_lesion_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "f = open(f\"{open_file}/{directory_name}/masterfile.txt\", \"w\")\n",
    "\n",
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name != training_folder):\n",
    "\n",
    "        print(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "        f.write(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "# Writing the test subject at the very end to correspond with the Training Command (in the upcoming code blocks)\n",
    "print(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "f.write(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the code block below could have been used for making use of the other two files, particularly the MNI Space Registration and the T1 to Flair Registration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(f\"{open_file}/{directory_name}/masterfile.txt\", \"w\")\n",
    "\n",
    "# for file in flairs:\n",
    "    \n",
    "#     folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "#     if(folder_name != training_folder):\n",
    "\n",
    "#         print(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_t1_to_flair.nii.gz {folder_name}/{folder_name}_flair_brain_to_MNI.mat {folder_name}/{folder_name}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "#         f.write(f\"{folder_name}/{folder_name}_flair_brain.nii.gz {folder_name}/{folder_name}_t1_to_flair.nii.gz {folder_name}/{folder_name}_flair_brain_to_MNI.mat {folder_name}/{folder_name}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "# # Writing the test subject at the very end to correspond with the Training Command (in the upcoming code blocks)\n",
    "# print(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_t1_to_flair.nii.gz {training_folder}/{training_folder}_flair_brain_to_MNI.mat {training_folder}/{training_folder}_flair_lesion_mask.nii.gz\")\n",
    "\n",
    "# f.write(f\"{training_folder}/{training_folder}_flair_brain.nii.gz {training_folder}/{training_folder}_t1_to_flair.nii.gz {training_folder}/{training_folder}_flair_brain_to_MNI.mat {training_folder}/{training_folder}_flair_lesion_mask.nii.gz \\n\")\n",
    "\n",
    "        \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The file should look similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject should have their individual entry on each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/masterfile_img.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Step: Training BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data to Train BIANCA, and it is linked in the Masterfile, we will move forward and train BIANCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17\n"
     ]
    }
   ],
   "source": [
    "training_nums = []\n",
    "for i in range(len(flairs)):\n",
    "    training_nums.append(i)\n",
    "\n",
    "t_nums = \",\".join([str(elem+1) for elem in training_nums])\n",
    "print(t_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 &&     bianca --singlefile=masterfile.txt --trainingnums=1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17 --labelfeaturenum=2     --querysubjectnum=17 --brainmaskfeaturenum=1     --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o ms_013_tp1/bianca_output     --saveclassifierdata=mytraining -v\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"cd {directory_1}/{directory_name} && \\\n",
    "    bianca --singlefile=masterfile.txt --trainingnums={t_nums} --labelfeaturenum=2 \\\n",
    "    --querysubjectnum={len(training_nums)} --brainmaskfeaturenum=1 \\\n",
    "    --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o {training_folder}/bianca_output \\\n",
    "    --saveclassifierdata=mytraining -v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below runs the Training Command for Bianca, and tests it on the very last image. There are numerous other query parameters that could be passed, which are detailed further here:\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA/Userguide#BIANCA_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 2 , number of possible training subjects = 17\n",
      "Files are: label file list = , data file list = ['masterfile.txt']\n",
      "Number of training points = 2000, mode = ['npoints', 'noborder']\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data\n",
      " ... reading label ms_002_tp1/ms_002_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_002_tp1/ms_002_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_003_tp1/ms_003_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_003_tp1/ms_003_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_003_tp6/ms_003_tp6_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_003_tp6/ms_003_tp6_flair_brain.nii.gz\n",
      " ... reading label ms_004_tp1/ms_004_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_004_tp1/ms_004_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_004_tp7/ms_004_tp7_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_004_tp7/ms_004_tp7_flair_brain.nii.gz\n",
      " ... reading label ms_006_tp1/ms_006_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_006_tp1/ms_006_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_006_tp3/ms_006_tp3_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_006_tp3/ms_006_tp3_flair_brain.nii.gz\n",
      " ... reading label ms_007_tp1/ms_007_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_007_tp1/ms_007_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_007_tp2/ms_007_tp2_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_007_tp2/ms_007_tp2_flair_brain.nii.gz\n",
      " ... reading label ms_008_tp1/ms_008_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_008_tp1/ms_008_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_008_tp6/ms_008_tp6_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_008_tp6/ms_008_tp6_flair_brain.nii.gz\n",
      " ... reading label ms_009_tp1/ms_009_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_009_tp1/ms_009_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_009_tp4/ms_009_tp4_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_009_tp4/ms_009_tp4_flair_brain.nii.gz\n",
      " ... reading label ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_010_tp1/ms_010_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_011_tp1/ms_011_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_011_tp1/ms_011_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_012_tp1/ms_012_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_012_tp1/ms_012_tp1_flair_brain.nii.gz\n",
      "Training data is size (181166, 1)\n",
      "Saving training data of size (181166, 1)\n",
      "Saving training data as  mytraining\n",
      "Loading query data\n",
      "  Query file list = ['ms_013_tp1/ms_013_tp1_flair_brain.nii.gz', 'ms_013_tp1/ms_013_tp1_flair_lesion_mask.nii.gz']\n",
      " ... reading label ms_013_tp1/ms_013_tp1_flair_lesion_mask.nii.gz\n",
      " ... no label found - ignoring\n",
      " ... reading image ms_013_tp1/ms_013_tp1_flair_brain.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    }
   ],
   "source": [
    "p = os.popen(\n",
    "    f\"cd {directory_1}/{directory_name} && \\\n",
    "    bianca --singlefile=masterfile.txt --trainingnums={t_nums} --labelfeaturenum=2 \\\n",
    "    --querysubjectnum={len(training_nums)} --brainmaskfeaturenum=1 \\\n",
    "    --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o {training_folder}/bianca_output \\\n",
    "    --saveclassifierdata=mytraining -v\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block commented below could be used for making use of all the 4 files that we generated, with the appropriate masterfile (the method of generation for which is also commented above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 2 , number of possible training subjects = 17\n",
      "Files are: label file list = , data file list = ['masterfile.txt']\n",
      "Number of training points = 2000, mode = ['npoints', 'noborder']\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data\n",
      " ... reading label ms_002_tp1/ms_002_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_002_tp1/ms_002_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_003_tp1/ms_003_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_003_tp1/ms_003_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_003_tp6/ms_003_tp6_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_003_tp6/ms_003_tp6_flair_brain.nii.gz\n",
      " ... reading label ms_004_tp1/ms_004_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_004_tp1/ms_004_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_004_tp7/ms_004_tp7_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_004_tp7/ms_004_tp7_flair_brain.nii.gz\n",
      " ... reading label ms_006_tp1/ms_006_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_006_tp1/ms_006_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_006_tp3/ms_006_tp3_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_006_tp3/ms_006_tp3_flair_brain.nii.gz\n",
      " ... reading label ms_007_tp1/ms_007_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_007_tp1/ms_007_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_007_tp2/ms_007_tp2_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_007_tp2/ms_007_tp2_flair_brain.nii.gz\n",
      " ... reading label ms_008_tp1/ms_008_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_008_tp1/ms_008_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_008_tp6/ms_008_tp6_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_008_tp6/ms_008_tp6_flair_brain.nii.gz\n",
      " ... reading label ms_009_tp1/ms_009_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_009_tp1/ms_009_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_009_tp4/ms_009_tp4_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_009_tp4/ms_009_tp4_flair_brain.nii.gz\n",
      " ... reading label ms_010_tp1/ms_010_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_010_tp1/ms_010_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_011_tp1/ms_011_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_011_tp1/ms_011_tp1_flair_brain.nii.gz\n",
      " ... reading label ms_012_tp1/ms_012_tp1_flair_lesion_mask.nii.gz\n",
      " ... reading image ms_012_tp1/ms_012_tp1_flair_brain.nii.gz\n",
      "Training data is size (181166, 1)\n",
      "Saving training data of size (181166, 1)\n",
      "Saving training data as  mytraining\n",
      "Loading query data\n",
      "  Query file list = ['ms_013_tp1/ms_013_tp1_flair_brain.nii.gz', 'ms_013_tp1/ms_013_tp1_flair_lesion_mask.nii.gz']\n",
      " ... reading label ms_013_tp1/ms_013_tp1_flair_lesion_mask.nii.gz\n",
      " ... no label found - ignoring\n",
      " ... reading image ms_013_tp1/ms_013_tp1_flair_brain.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    }
   ],
   "source": [
    "# p = os.popen(\n",
    "#     f\"cd {directory_1}/{directory_name} && \\\n",
    "#     bianca --singlefile=masterfile.txt --trainingnums={t_nums} --labelfeaturenum=4 \\\n",
    "#     --querysubjectnum={len(training_nums)} --brainmaskfeaturenum=1 --featuresubset=1,2 --matfeaturenum=3 \\\n",
    "#     --trainingpts=2000 --nonlespts=10000 --selectpts=noborder -o {training_folder}/bianca_output \\\n",
    "#     --saveclassifierdata=mytraining -v\")\n",
    "# if p:\n",
    "#     output = p.read()\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the above code block ran successfully, we have successfully ran and stored the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, as a final step, we will move ahead and produce a file which contains some basic information, or metadata in proper terminology, from the training so that it could be used when we are testing using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information we need to store is the reference dimension and the reference image with that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('256', '256', '40')\n"
     ]
    }
   ],
   "source": [
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_file = open(f\"{open_file}/{directory_name}/metadata.txt\", \"w\")\n",
    "storage_file.write(f\"{most_freq[0]},{most_freq[1]},{most_freq[2]}\\n\")\n",
    "storage_file.write(f\"{ref_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is needed to build on top of our BIANCA output. The purpose that it would serve is to allow for a dynamic way of applying a threshold, rather than a Binary method of doing so - which would have led to discrepancies in our results.\n",
    "\n",
    "https://git.fmrib.ox.ac.uk/vaanathi/LOCATE-BIANCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCATE is a supervised method and hence requires data for training. In the current version the user needs to provide data in a specific, standardized manner (which can typically be achieved by some moving and renaming of files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Creating the Directory & Sub Directories for Training/ Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training-2022-12-04'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04\n"
     ]
    }
   ],
   "source": [
    "print(open_file + \"/\" + training_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "directory_name = 'LOCATE_Training-' + str(today)\n",
    "\n",
    "# Creating the Parent Directory\n",
    "path = os.path.join(open_file + \"/\" + training_directory_name, directory_name)\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    \n",
    "# Creating the Training Sub-Directory\n",
    "path = os.path.join(open_file + \"/\" + training_directory_name + \"/\"+directory_name, \"Training_imgs_directory\")\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    \n",
    "    \n",
    "# Creating the Training Sub-Directory\n",
    "path = os.path.join(open_file + \"/\" + training_directory_name + \"/\"+directory_name, \"Test_imgs_directory\")\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    \n",
    "# Creating the Sub-Directory for any other processing required\n",
    "path = os.path.join(open_file + \"/\" + training_directory_name + \"/\"+directory_name, \"Processing\")\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Preparing the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain results from LOCATE, we need to prepare some files which make use of the data that we already have present, but some additional pre processing on it to generate intermediary files that will be used to train LOCATE.\n",
    "\n",
    "The required images are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The base image modality used in BIANCA ---\n",
    "'(subject_name)-feature-(base_modality_name).nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-013-tp1\n"
     ]
    }
   ],
   "source": [
    "print(training_subject_bianca.replace(\"_\",\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp ms_013_tp1/ms_013_tp1_flair_brain.nii.gz LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"cd {directory_1}/{training_directory_name} && cp {folder_name}/{file} {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "\n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    p = os.popen(\n",
    "    f\"cd {directory_1}/{training_directory_name} && cp {folder_name}/{file} {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.gz\")\n",
    "\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next file is optional, and since we are not making use of T1 Images or the MNI Space Registered Images, we will be skipping this part.\n",
    "\n",
    "2. Any other additional images that were used as intensity features in BIANCA (--\n",
    "featuresubset) (optional)\n",
    "<subject_name>_feature_<modality_name>.nii.gz\n",
    "(eg. <subject_name>_feature_T1.nii.gz, please note that it is mandatory to add\n",
    "_feature_ in the filename before the modality name for it to be considered as a\n",
    "feature)\n",
    "__(OPTIONAL)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had manually labelled lesion masks for the training of BIANCA, we will be using them in this step as well:\n",
    "\n",
    "3. Lesion Manual mask (for training subjects only): binary mask (values of 0 and 1) indicating lesion voxels, based on manual segmentation --- (subject_name)_manualmask.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_folder = \"Training_imgs_directory\"\n",
    "for mask in masks:\n",
    "\n",
    "    folder_name = \"_\".join(mask.split('_')[0:3])\n",
    "    folder_name_fixed = \"-\".join(mask.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        p = os.popen(\n",
    "        f\"cd {directory_1}/{training_directory_name} && cp {folder_name}/{mask} {directory_name}/{training_folder}/{folder_name_fixed}_manualmask.nii.gz\")\n",
    "\n",
    "        if p:\n",
    "            output = p.read()\n",
    "            print(output)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ventricle distance map: image where each voxel intensity represents the distance\n",
    "from ventricles within the brain mask (this can be calculated using the FSL tool\n",
    "distancemap – see the wiki for more details, example call: distancemap -i\n",
    "<ventricle_mask_image_in_FLAIR_space> -m <brain_mask_in_FLAIR_space> -o\n",
    "<subject_name>_ventdistmap.nii.gz)\n",
    " <subject_name>_ventdistmap.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_csf_pve.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o LOCATE_Training-2022-12-04/Processing LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_feature_FLAIR.nii.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && cp LOCATE_Training-2022-12-04/Processing/_pve_0.nii.gz LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_csf_pve.nii.gz\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run FSL Fast to get the CSF pve file\n",
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    print(f\"cd {directory_1}/{training_directory_name} && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {directory_name}/Processing {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.nii.gz\")\n",
    "    print()\n",
    "    print(f\"cd {directory_1}/{training_directory_name} && cp {directory_name}/Processing/_pve_0.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")\n",
    "    print()\n",
    "    \n",
    "    p = os.popen(\n",
    "    f\"cd {directory_1}/{training_directory_name} && /Applications/fsl/bin/fast -t 1 -n 3 -H 0.1 -I 4 -l 20.0 -o {directory_name}/Processing/ {directory_name}/{training_folder}/{folder_name_fixed}_feature_FLAIR.nii.nii.gz\")\n",
    "\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)  \n",
    "    \n",
    "\n",
    "    p = os.popen(\n",
    "    f\"cd {directory_1}/{training_directory_name} && cp {directory_name}/Processing/_pve_0.nii.gz {directory_name}/{training_folder}/{folder_name_fixed}_csf_pve.nii.gz\")\n",
    "\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flirt -ref MNI152_2mm_brain.nii.gz -in ms-002-tp1_feature_FLAIR.nii.gz -omat my_affine_transf.mat\n",
    "\n",
    "\n",
    "fnirt --in=ms-002-tp1_feature_FLAIR.nii.gz --aff=my_affine_transf.mat --cout=my_nonlinear_transf --config=T1_2_MNI152_2mm\n",
    "\n",
    "applywarp --ref=MNI152_2mm_brain.nii.gz --in=ms-002-tp1_feature_FLAIR.nii.gz --warp=my_nonlinear_transf --out=my_warped_structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the warp_file_MNI2structural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # distancemap \n",
    "# # -i <ventricle_mask_image_in_FLAIR_space> \n",
    "# # -m <brain_mask_in_FLAIR_space> \n",
    "# # -o <subject_name>_ventdistmap.nii.gz)\n",
    "\n",
    "# We need to obtain the ventricle mask image in FLAIR Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIANCA Output for all files\n",
    "From the above training of BIANCA, we obtained some training files which we are going to use to generate bianca outputs for all of the files that we used for the training\n",
    "\n",
    "5. BIANCA output: unthresholded lesion probability map (LPM) obtained from\n",
    "BIANCA\n",
    "(subject_name)_BIANCA_LPM.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-002-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-002-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-002-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-003-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-003-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-003-tp6_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-003-tp6_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-003-tp6_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-004-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-004-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-004-tp7_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-004-tp7_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-004-tp7_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-006-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-006-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-006-tp3_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-006-tp3_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-006-tp3_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-007-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-007-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-007-tp2_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-007-tp2_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-007-tp2_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-008-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-008-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-008-tp6_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-008-tp6_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-008-tp6_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-009-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-009-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-009-tp4_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-009-tp4_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-009-tp4_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-010-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-010-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-010-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-011-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-011-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-011-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-012-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-012-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Training_imgs_directory/ms-012-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n",
      "LOCATE_Training-2022-12-04/Training_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-013-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Training_imgs_directory/ms-013-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-013-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Training_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Applications/fsl/fslpython/envs/fslpython/lib/python3.7/site-packages/nibabel/loadsave.py\", line 40, in load\n",
      "    stat_result = os.stat(filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'LOCATE_Training-2022-12-04/Training_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/fsl/bin/bianca\", line 1033, in <module>\n",
      "    p_main()\n",
      "  File \"/Applications/fsl/bin/bianca\", line 999, in p_main\n",
      "    [check_dat,querypts,_] = load_vox_data([queryfilelist],matfilelist=[querymat],labelfilelist=querylabel,mode=['allpoints'],spatial_features=GlobalOpts.spatial_features,use_labels=False)\n",
      "  File \"/Applications/fsl/bin/bianca\", line 557, in load_vox_data\n",
      "    imobj = nib.load(filelist[GlobalOpts.maskfeaturenum])\n",
      "  File \"/Applications/fsl/fslpython/envs/fslpython/lib/python3.7/site-packages/nibabel/loadsave.py\", line 42, in load\n",
      "    raise FileNotFoundError(\"No such file or no access: '%s'\" % filename)\n",
      "FileNotFoundError: No such file or no access: 'LOCATE_Training-2022-12-04/Training_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz'\n"
     ]
    }
   ],
   "source": [
    "file_path = (f\"{open_file}/{training_directory_name}\").replace(\" \", \"\\ \")\n",
    "classifier = file_path + \"/mytraining\"\n",
    "print(\"Classifier: \",classifier)\n",
    "print()\n",
    "\n",
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"-\".join(file.split('_')[0:3])\n",
    "\n",
    "    masterfile = f\"{open_file}/{training_directory_name}/{directory_name}/Processing/{folder_name}_masterfile.txt\"\n",
    "\n",
    "    print(f\"{directory_name}/Training_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "    print()\n",
    "    file = open(masterfile, 'w')\n",
    "    file.write(f\"{directory_name}/Training_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "    file.close()\n",
    "    \n",
    "    masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "    bianca_output = f\"{folder_name}_BIANCA_LPM.nii.gz\"\n",
    "    \n",
    "    print(f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Training_imgs_directory/{bianca_output} -v\")\n",
    "    print()\n",
    "    \n",
    "    p = os.popen(\n",
    "        f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Training_imgs_directory/{bianca_output} -v\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Testing File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04 && bianca --singlefile=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-013-tp1_masterfile.txt --loadclassifierdata=/Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/mytraining --querysubjectnum=1 --brainmaskfeaturenum=1 -o LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_BIANCA_LPM.nii.gz -v\n",
      "\n",
      "Number of modalities = 1 , number of possible training subjects = 1\n",
      "Files are: label file list = , data file list = ['/Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Processing/ms-013-tp1_masterfile.txt']\n",
      "Number of training points = 2000, mode = []\n",
      "no spatial features used\n",
      "Using all available images as intensity features (no intensity features subset specified)\n",
      "Loading training data  /Volumes/MS_training/Automated BIANCA Training/All_Files/Training-2022-12-04/mytraining\n",
      "Training data is size (181166, 1)\n",
      "Loading query data\n",
      "  Query file list = ['LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz']\n",
      " ... reading image LOCATE_Training-2022-12-04/Test_imgs_directory/ms-013-tp1_feature_FLAIR.nii.gz\n",
      "Training classifier\n",
      "Applying classifier\n",
      "Calculating p-values\n",
      "Saving output image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/fsl/bin/bianca:558: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  GlobalOpts.pixdims=imobj.get_header().get_zooms()\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n",
      "/Applications/fsl/bin/bianca:1026: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  pnii = nib.Nifti1Image(pvalim,queryimcl.get_affine(),header=queryimcl.get_header())\n"
     ]
    }
   ],
   "source": [
    "file = flairs[len(flairs)-1]\n",
    "\n",
    "folder_name = \"-\".join(file.split('_')[0:3])\n",
    "\n",
    "masterfile = f\"{open_file}/{training_directory_name}/{directory_name}/Processing/{folder_name}_masterfile.txt\"\n",
    "\n",
    "print(f\"{directory_name}/Test_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "print()\n",
    "file = open(masterfile, 'w')\n",
    "file.write(f\"{directory_name}/Test_imgs_directory/{folder_name}_feature_FLAIR.nii.gz\")\n",
    "file.close()\n",
    "\n",
    "masterfile=masterfile.replace(\" \", \"\\ \")\n",
    "bianca_output = f\"{folder_name}_BIANCA_LPM.nii.gz\"\n",
    "\n",
    "print(f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Test_imgs_directory/{bianca_output} -v\")\n",
    "print()\n",
    "\n",
    "p = os.popen(\n",
    "    f\"cd {file_path} && bianca --singlefile={masterfile} --loadclassifierdata={classifier} --querysubjectnum=1 --brainmaskfeaturenum=1 -o {directory_name}/Test_imgs_directory/{bianca_output} -v\")\n",
    "if p:\n",
    "    output = p.read()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple fslmaths command, we will obtain a mask for the Extracted Brain images that we already have\n",
    "\n",
    "6. Brain mask: binary mask obtained from FSL-BET or any other method\n",
    "<subject_name>_brainmask.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-002-tp1_feature_FLAIR.nii.gz -bin ms-002-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-003-tp1_feature_FLAIR.nii.gz -bin ms-003-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-003-tp6_feature_FLAIR.nii.gz -bin ms-003-tp6_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-004-tp1_feature_FLAIR.nii.gz -bin ms-004-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-004-tp7_feature_FLAIR.nii.gz -bin ms-004-tp7_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-006-tp1_feature_FLAIR.nii.gz -bin ms-006-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-006-tp3_feature_FLAIR.nii.gz -bin ms-006-tp3_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-007-tp1_feature_FLAIR.nii.gz -bin ms-007-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-007-tp2_feature_FLAIR.nii.gz -bin ms-007-tp2_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-008-tp1_feature_FLAIR.nii.gz -bin ms-008-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-008-tp6_feature_FLAIR.nii.gz -bin ms-008-tp6_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-009-tp1_feature_FLAIR.nii.gz -bin ms-009-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-009-tp4_feature_FLAIR.nii.gz -bin ms-009-tp4_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-010-tp1_feature_FLAIR.nii.gz -bin ms-010-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-011-tp1_feature_FLAIR.nii.gz -bin ms-011-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Training_imgs_directory && fslmaths ms-012-tp1_feature_FLAIR.nii.gz -bin ms-012-tp1_brainmask.nii.gz\n",
      "\n",
      "cd /Volumes/MS_training/Automated\\ BIANCA\\ Training/All_Files/Training-2022-12-04/LOCATE_Training-2022-12-04/Test_imgs_directory && fslmaths ms-013-tp1_feature_FLAIR.nii.gz -bin ms-013-tp1_brainmask.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in flairs:\n",
    "    \n",
    "    folder_name = \"_\".join(file.split('_')[0:3])\n",
    "    \n",
    "    if(folder_name!=training_subject_bianca):\n",
    "        training_folder = \"Training_imgs_directory\"\n",
    "    else:\n",
    "        training_folder = \"Test_imgs_directory\"\n",
    "    \n",
    "    folder_name_fixed = \"-\".join(file.split('_')[0:3])\n",
    "    \n",
    "    print(f\"cd {file_path}/{directory_name}/{training_folder} && fslmaths {folder_name_fixed}_feature_FLAIR.nii.gz -bin {folder_name_fixed}_brainmask.nii.gz\")\n",
    "    p = os.popen(\n",
    "        f\"cd {file_path}/{directory_name}/{training_folder} && fslmaths {folder_name_fixed}_feature_FLAIR.nii.gz -bin {folder_name_fixed}_brainmask.nii.gz\")\n",
    "    if p:\n",
    "        output = p.read()\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. BIANCA mask: binary mask, as obtained from make_bianca_mask (white matter\n",
    "mask excluding sub-cortical regions) - If you are not using BIANCA mask in your\n",
    "analysis, make a copy of the brain mask and rename it as BIANCA mask.\n",
    " <subject_name>_biancamask.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
